{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Add the directory where dynamics.py and utils.py are located to sys.path\n",
    "module_path = os.path.abspath(os.path.join('../../src'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from tqdm import tqdm\n",
    "from dynamics import SatelliteDynamics\n",
    "from scipy.linalg import block_diag\n",
    "from utils import get_form_initial_conditions\n",
    "from unkkt import UNKKT\n",
    "from approxh_newton import approxH_Newton\n",
    "from mm_newton import MM_Newton\n",
    "from concurrent.futures import ProcessPoolExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulation parameters\n",
    "dt = 60.0  # Time step [s]\n",
    "T = 395  # Duration [min]\n",
    "M = 1  # Number of Monte-Carlo simulations\n",
    "N = 4  # Number of satellites\n",
    "formation = 1\n",
    "n_x = 6  # Number of states\n",
    "n_p = 3  \n",
    "n_y_1 = 3  # Number of measurements\n",
    "n_y_2 = 2\n",
    "n_y_3 = 2\n",
    "n_y_4 = 2\n",
    "K = T\n",
    "W = 100 # Window size [min]\n",
    "dynamic_model = SatelliteDynamics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial state vector and get the true state vectors (propagation) F\n",
    "X_initial = get_form_initial_conditions(formation)\n",
    "X_true = np.zeros((24, 1, T))\n",
    "X_true[:, :, 0] = X_initial\n",
    "for t in range(T - 1):\n",
    "    X_true[:, :, t + 1] = SatelliteDynamics().x_new(dt, X_true[:, :, t])\n",
    "\n",
    "# Process noise\n",
    "q_chief_pos = 1e-1  # [m]\n",
    "q_chief_vel = 1e-2 # [m / s]\n",
    "Q_chief = (\n",
    "    np.diag(np.concatenate([q_chief_pos * np.ones(3), q_chief_vel * np.ones(3)]))\n",
    "    ** 2\n",
    ")\n",
    "q_deputy_pos = 1e0  # [m]\n",
    "q_deputy_vel = 1e-2  # [m / s]\n",
    "Q_deputy = (\n",
    "    np.diag(np.concatenate([q_deputy_pos * np.ones(3), q_deputy_vel * np.ones(3)]))\n",
    "    ** 2\n",
    ")\n",
    "Q_deputies = block_diag(Q_deputy, Q_deputy, Q_deputy)\n",
    "Q = block_diag(Q_chief, Q_deputies)\n",
    "\n",
    "# Observation noise\n",
    "r_chief_pos = 1e-1  # [m]\n",
    "R_chief = np.diag(np.concatenate([r_chief_pos * np.ones(3)])) ** 2\n",
    "r_deputy_pos = 1e0  # [m]\n",
    "R_deputies = np.diag(np.concatenate([r_deputy_pos * np.ones(6)])) ** 2\n",
    "R = block_diag(R_chief, R_deputies)\n",
    "\n",
    "# Initial deviation noise\n",
    "p_pos_initial = 1e2  # [m]\n",
    "p_vel_initial = 1e-2  # [m / s]\n",
    "P = np.array([[1, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tol = 1e-20\n",
    "max_iter = 100\n",
    "\n",
    "# Declare solvers\n",
    "unkkt = UNKKT(W, R_chief, r_deputy_pos)\n",
    "unkkt.grad_tol = tol\n",
    "unkkt.max_iter = max_iter\n",
    "\n",
    "approxh_newton = approxH_Newton(W, R_chief, r_deputy_pos)\n",
    "approxh_newton.grad_tol = tol\n",
    "approxh_newton.max_iter = max_iter\n",
    "\n",
    "mm_newton = MM_Newton(W, R_chief, r_deputy_pos)\n",
    "mm_newton.grad_tol = tol\n",
    "mm_newton.max_iter = max_iter\n",
    "mm_newton.mm_tol = tol\n",
    "mm_newton.mm_max_iter = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixed seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "X_est = np.zeros_like(X_true)\n",
    "initial_dev = np.concatenate(\n",
    "    (\n",
    "        p_pos_initial * np.random.randn(3, 1),\n",
    "        p_vel_initial * np.random.randn(3, 1),\n",
    "        p_pos_initial * np.random.randn(3, 1),\n",
    "        p_vel_initial * np.random.randn(3, 1),\n",
    "        p_pos_initial * np.random.randn(3, 1),\n",
    "        p_vel_initial * np.random.randn(3, 1),\n",
    "        p_pos_initial * np.random.randn(3, 1),\n",
    "        p_vel_initial * np.random.randn(3, 1),\n",
    "    )\n",
    ")\n",
    "X_est[:, :, 0] = X_initial + initial_dev\n",
    "for t in range(T - 1):\n",
    "    X_est[:, :, t + 1] = SatelliteDynamics().x_new(dt, X_est[:, :, t])\n",
    "\n",
    "# Observations\n",
    "Y = np.zeros((9, 1, T))\n",
    "for t in range(T):\n",
    "    Y[:, :, t] = unkkt.h(X_true[:, :, t]) + np.random.normal(0, np.sqrt(np.diag(R)).reshape((9, 1)), size=(9, 1))\n",
    "    \n",
    "dev_chief_initial = np.linalg.norm(X_est[:3, :, :] - X_true[:3, :, :], axis=0).reshape(-1, 1)\n",
    "dev_deputy1_initial = np.linalg.norm(X_est[6:9, :, :] - X_true[6:9, :, :], axis=0).reshape(-1, 1)\n",
    "dev_deputy2_initial = np.linalg.norm(X_est[12:15, :, :] - X_true[12:15, :, :], axis=0).reshape(-1, 1)\n",
    "dev_deputy3_initial = np.linalg.norm(X_est[18:21, :, :] - X_true[18:21, :, :], axis=0).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MC runs:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Windows:   0%|          | 0/296 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Centralized Newton ---------------- MM Newton ---------------- ApproxH Newton --------\n",
      "\n",
      "\n",
      "\n",
      "Majorization-Minimization Iteration 1\n",
      "Before applying the algorithm\n",
      "L_norm = 27666223.18644657\n",
      "Grad_L_norm = 758929245.3026879\n",
      "\n",
      "Before applying the algorithm\n",
      "Cost function: 27666223.18644657\n",
      "Gradient norm: 758929245.3026879\n",
      "Global relative error: 395.60563949432424\n",
      "Position relative errors: 82.78540989608044 m, 181.7491507333766 m, 258.73787052498585 m, 222.8729633755392 m\n",
      "\n",
      "Iteration 1\n",
      "L_norm = 382675.94479547284\n",
      "Grad_L_norm = 4552671.641381741\n",
      "Iteration 1\n",
      "Cost function: 1448197.7255343578 (-94.77%)\n",
      "Gradient norm: 19734607.97656045 (-97.40%)\n",
      "Global relative error: 2210.5086286598125 (458.77%)\n",
      "\n",
      "Position relative errors: 7.741842214609515 m, 1755.1033228520973 m, 789.6276820304671 m, 1087.3745448761824 m\n",
      "\n",
      "Before applying the algorithm\n",
      "Cost function: 27666223.186446577\n",
      "Gradient norm: 758929245.3026879\n",
      "Global relative error: 395.60563949432424\n",
      "Position relative errors: 82.78540989608044 m, 181.7491507333766 m, 258.73787052498585 m, 222.8729633755392 m\n",
      "\n",
      "Iteration 2\n",
      "Cost function: 321102.13589202584 (-77.83%)\n",
      "Gradient norm: 10893002.54291408 (-44.80%)\n",
      "Global relative error: 1083.2394998787727 (-51.00%)\n",
      "Position relative errors: 2.080033931317147 m, 879.2649100147914 m, 448.883194896402 m, 445.8699129549396 m\n",
      "\n",
      "Iteration 2\n",
      "L_norm = 16242.877740284925\n",
      "Grad_L_norm = 591469.434916945\n",
      "\n",
      "Iteration 3\n",
      "Cost function: 184894.8940278097 (-42.42%)\n",
      "Gradient norm: 6821105.9162244145 (-37.38%)\n",
      "Global relative error: 812.3701231261517 (-25.01%)\n",
      "Position relative errors: 0.9372704102153653 m, 435.966787910987 m, 432.17918146461653 m, 532.069107567891 m\n",
      "\n",
      "Iteration 3\n",
      "L_norm = 2604.209842021173\n",
      "Grad_L_norm = 50548.53743711634\n",
      "\n",
      "Iteration 1\n",
      "Cost function: 3169927.5936511774 (-88.54%)\n",
      "Gradient norm: 332306.5062691289 (-99.96%)\n",
      "Global relative error: 385.363659758873 (-2.59%)\n",
      "Position relative errors: 2.220525709929342 m, 182.73365578337578 m, 236.67769866708463 m, 243.08851615501803 m\n",
      "\n",
      "Iteration 4\n",
      "Cost function: 69393.55794302402 (-62.47%)\n",
      "Gradient norm: 4009776.1293985434 (-41.22%)\n",
      "Global relative error: 713.6578778740653 (-12.15%)\n",
      "Position relative errors: 0.7742969156597086 m, 430.65080199485783 m, 407.03550301653206 m, 397.7042400936264 m\n",
      "\n",
      "Iteration 4\n",
      "L_norm = 380.70408811480144\n",
      "Grad_L_norm = 21179.24144316136\n",
      "\n",
      "Iteration 5\n",
      "Cost function: 68262.26559661809 (-1.63%)\n",
      "Gradient norm: 2877593.9060758445 (-28.24%)\n",
      "Global relative error: 755.6201073904613 (5.88%)\n",
      "Position relative errors: 0.9086079630768981 m, 375.4303637149821 m, 508.5904431160233 m, 413.942321143875 m\n",
      "\n",
      "Iteration 5\n",
      "L_norm = 22.217303272750478\n",
      "Grad_L_norm = 6059.464303398231\n",
      "\n",
      "Iteration 2\n",
      "Cost function: 3169850.7008254086 (-0.00%)\n",
      "Gradient norm: 18.570360135042105 (-99.99%)\n",
      "Global relative error: 386.66028700959055 (0.34%)\n",
      "Position relative errors: 2.1733304891455147 m, 183.52474980761997 m, 237.3326449639186 m, 243.91199688002135 m\n",
      "\n",
      "Iteration 6\n",
      "Cost function: 33289.07308353023 (-51.23%)\n",
      "Gradient norm: 1793276.312255132 (-37.68%)\n",
      "Global relative error: 663.0197035240732 (-12.25%)\n",
      "Position relative errors: 0.5865925366327258 m, 394.965351626091 m, 390.36307214598514 m, 362.2341907242922 m\n",
      "\n",
      "Iteration 6\n",
      "L_norm = 4.416178465996703\n",
      "Grad_L_norm = 305.14276217733595\n",
      "\n",
      "Iteration 7\n",
      "Cost function: 33163.183828363224 (-0.38%)\n",
      "Gradient norm: 1496513.5357672116 (-16.55%)\n",
      "Global relative error: 641.1301691596044 (-3.30%)\n",
      "Position relative errors: 0.5101563964489501 m, 349.8142050831668 m, 409.7710310265075 m, 347.51277082840204 m\n",
      "\n",
      "Iteration 7\n",
      "L_norm = 4.381432949232987\n",
      "Grad_L_norm = 0.4610025316114664\n",
      "\n",
      "Iteration 3\n",
      "Cost function: 3169850.7008261024 (0.00%)\n",
      "Gradient norm: 0.05442584952468073 (-99.71%)\n",
      "Global relative error: 386.6603175704216 (0.00%)\n",
      "Position relative errors: 2.173331707526417 m, 183.52476697274062 m, 237.3326590066396 m, 243.91201873593144 m\n",
      "\n",
      "Iteration 8\n",
      "Cost function: 19070.348769542452 (-42.50%)\n",
      "Gradient norm: 1019421.9441304941 (-31.88%)\n",
      "Global relative error: 574.8281807032719 (-10.34%)\n",
      "Position relative errors: 0.2856116929593559 m, 330.06178607180914 m, 335.31244929987685 m, 330.23020966461337 m\n",
      "\n",
      "Iteration 8\n",
      "L_norm = 4.38143280460879\n",
      "Grad_L_norm = 0.04641170193023029\n",
      "\n",
      "Iteration 9\n",
      "Cost function: 17933.735644116085 (-5.96%)\n",
      "Gradient norm: 929905.8694672408 (-8.78%)\n",
      "Global relative error: 545.8688486164444 (-5.04%)\n",
      "Position relative errors: 0.30920401022361316 m, 303.98684700848196 m, 347.29076616654874 m, 291.46817989912006 m\n",
      "\n",
      "Iteration 9\n",
      "L_norm = 4.3814328026221805\n",
      "Grad_L_norm = 0.01599179130462676\n",
      "\n",
      "Iteration 4\n",
      "Cost function: 3169850.7008258807 (-0.00%)\n",
      "Gradient norm: 0.01855440412492328 (-65.91%)\n",
      "Global relative error: 386.66031757250164 (0.00%)\n",
      "Position relative errors: 2.1733316993619725 m, 183.5247669742835 m, 237.3326590068455 m, 243.9120187379402 m\n",
      "\n",
      "Iteration 10\n",
      "Cost function: 11270.590230679465 (-37.15%)\n",
      "Gradient norm: 684567.7267926513 (-26.38%)\n",
      "Global relative error: 495.8082414089057 (-9.17%)\n",
      "Position relative errors: 0.196328359302787 m, 280.8012582628145 m, 286.1815108778668 m, 291.67872351201726 m\n",
      "\n",
      "Iteration 10\n",
      "L_norm = 4.381432802682849\n",
      "Grad_L_norm = 0.004941603722004816\n",
      "\n",
      "Iteration 11\n",
      "Cost function: 10103.502574861119 (-10.36%)\n",
      "Gradient norm: 641578.7044709175 (-6.28%)\n",
      "Global relative error: 469.52459454175283 (-5.30%)\n",
      "Position relative errors: 0.22499904742323448 m, 262.5908304221896 m, 300.60797681143697 m, 247.25315285044252 m\n",
      "\n",
      "Iteration 11\n",
      "L_norm = 4.381432802370183\n",
      "Grad_L_norm = 0.016015416879077968\n",
      "\n",
      "Iteration 5\n",
      "Cost function: 3169850.700828193 (0.00%)\n",
      "Gradient norm: 0.011065137244708914 (-40.36%)\n",
      "Global relative error: 386.6603175653464 (-0.00%)\n",
      "Position relative errors: 2.173331695268085 m, 183.52476696940164 m, 237.33265900752514 m, 243.91201872964578 m\n",
      "\n",
      "Iteration 12\n",
      "Cost function: 6754.515507657195 (-33.15%)\n",
      "Gradient norm: 499047.44718069496 (-22.22%)\n",
      "Global relative error: 428.75174058950915 (-8.68%)\n",
      "Position relative errors: 0.16608069948087525 m, 241.1189476573009 m, 245.64282019640558 m, 255.63494544975507 m\n",
      "\n",
      "Iteration 12\n",
      "L_norm = 4.3814328023701\n",
      "Grad_L_norm = 0.05173027566081464\n",
      "\n",
      "Iteration 13\n",
      "Cost function: 5855.063838050517 (-13.32%)\n",
      "Gradient norm: 465708.03781164205 (-6.68%)\n",
      "Global relative error: 405.80733491782416 (-5.35%)\n",
      "Position relative errors: 0.17978623969228108 m, 227.04501452428508 m, 261.37369710093304 m, 211.6928624716324 m\n",
      "\n",
      "Iteration 13\n",
      "L_norm = 4.38143280383667\n",
      "Grad_L_norm = 0.033806679011410566\n",
      "\n",
      "Iteration 6\n",
      "Cost function: 3169850.7008260097 (-0.00%)\n",
      "Gradient norm: 0.015098045367349374 (36.45%)\n",
      "Global relative error: 386.66031757405204 (0.00%)\n",
      "Position relative errors: 2.1733316930290725 m, 183.5247669757869 m, 237.33265900826314 m, 243.9120187379437 m\n",
      "\n",
      "Iteration 14\n",
      "Cost function: 4101.140846720831 (-29.96%)\n",
      "Gradient norm: 375959.60256418836 (-19.27%)\n",
      "Global relative error: 371.59447624334325 (-8.43%)\n",
      "Position relative errors: 0.14906355953464878 m, 207.89075324963537 m, 211.80736876692924 m, 223.6100749121792 m\n",
      "\n",
      "Iteration 14\n",
      "L_norm = 4.381432804329218\n",
      "Grad_L_norm = 0.011282977596556032\n",
      "\n",
      "Iteration 15\n",
      "Cost function: 3476.803878368688 (-15.22%)\n",
      "Gradient norm: 346235.61516908434 (-7.91%)\n",
      "Global relative error: 351.610703713158 (-5.38%)\n",
      "Position relative errors: 0.15002331226715065 m, 196.61688148729587 m, 227.33686535129158 m, 182.45489146275884 m\n",
      "\n",
      "Iteration 15\n",
      "L_norm = 4.381432803970872\n",
      "Grad_L_norm = 0.0220651915755205\n",
      "\n",
      "Iteration 7\n",
      "Cost function: 3169850.7008261885 (0.00%)\n",
      "Gradient norm: 0.043043294007869104 (185.09%)\n",
      "Global relative error: 386.6603175686316 (-0.00%)\n",
      "Position relative errors: 2.173331702277272 m, 183.52476697665557 m, 237.33265900724365 m, 243.9120187296071 m\n",
      "\n",
      "Iteration 16\n",
      "Cost function: 2525.897106694901 (-27.35%)\n",
      "Gradient norm: 286918.3691820516 (-17.13%)\n",
      "Global relative error: 322.50752507690254 (-8.28%)\n",
      "Position relative errors: 0.1362216329479654 m, 179.61877613027158 m, 183.23930801978423 m, 195.3753023513196 m\n",
      "\n",
      "Iteration 16\n",
      "L_norm = 4.38143280130236\n",
      "Grad_L_norm = 0.02219475995607433\n",
      "\n",
      "Iteration 17\n",
      "Cost function: 2112.175171499287 (-16.38%)\n",
      "Gradient norm: 260625.16366778212 (-9.16%)\n",
      "Global relative error: 305.0601368221003 (-5.41%)\n",
      "Position relative errors: 0.12842525602918536 m, 170.45456078743703 m, 197.607972046867 m, 157.98095930010362 m\n",
      "\n",
      "Iteration 17\n",
      "L_norm = 4.381432802790722\n",
      "Grad_L_norm = 0.04713797573643785\n",
      "\n",
      "Iteration 8\n",
      "Cost function: 3169850.7008267785 (0.00%)\n",
      "Gradient norm: 0.05349848065169245 (24.29%)\n",
      "Global relative error: 386.660317567203 (-0.00%)\n",
      "Position relative errors: 2.173331703805932 m, 183.52476697345188 m, 237.3326590064722 m, 243.9120187304899 m\n",
      "\n",
      "Iteration 18\n",
      "Cost function: 1580.3543772051632 (-25.18%)\n",
      "Gradient norm: 220262.48186249728 (-15.49%)\n",
      "Global relative error: 280.1355787122307 (-8.17%)\n",
      "Position relative errors: 0.1251691578567718 m, 155.39131522946093 m, 158.91475745727428 m, 170.5155307693102 m\n",
      "\n",
      "Iteration 18\n",
      "L_norm = 4.381432800840984\n",
      "Grad_L_norm = 0.0032249876921950542\n",
      "\n",
      "Iteration 19\n",
      "Cost function: 1311.7512608938764 (-17.00%)\n",
      "Gradient norm: 197659.89530846363 (-10.26%)\n",
      "Global relative error: 264.869597004941 (-5.45%)\n",
      "Position relative errors: 0.1120617112991813 m, 147.86524271561998 m, 171.64049319442523 m, 137.22714226525764 m\n",
      "\n",
      "Iteration 19\n",
      "L_norm = 4.381432805548086\n",
      "Grad_L_norm = 0.08237469935412203\n",
      "\n",
      "Iteration 9\n",
      "Cost function: 3169850.7008261792 (-0.00%)\n",
      "Gradient norm: 0.01562863381908046 (-70.79%)\n",
      "Global relative error: 386.66031756881557 (0.00%)\n",
      "Position relative errors: 2.17333170116424 m, 183.5247669725267 m, 237.33265900912386 m, 243.91201873118578 m\n",
      "\n",
      "Iteration 20\n",
      "Cost function: 1005.6468795183104 (-23.34%)\n",
      "Gradient norm: 169702.60458775412 (-14.14%)\n",
      "Global relative error: 243.4597112633597 (-8.08%)\n",
      "Position relative errors: 0.11515261188370703 m, 134.5624760055195 m, 138.08422457366282 m, 148.6549377711478 m\n",
      "\n",
      "Iteration 20\n",
      "L_norm = 4.381432801738979\n",
      "Grad_L_norm = 0.04340064864153418\n",
      "\n",
      "Iteration 21\n",
      "Cost function: 832.401815091539 (-17.23%)\n",
      "Gradient norm: 150695.18105546338 (-11.20%)\n",
      "Global relative error: 230.08240186692495 (-5.49%)\n",
      "Position relative errors: 0.09940781876393272 m, 128.31199643036723 m, 148.99722528427904 m, 119.47280245157857 m\n",
      "\n",
      "Iteration 21\n",
      "L_norm = 4.381432804756622\n",
      "Grad_L_norm = 0.020290139416738604\n",
      "\n",
      "Iteration 10\n",
      "Cost function: 3169850.7008270114 (0.00%)\n",
      "Gradient norm: 0.02714999334905239 (73.72%)\n",
      "Global relative error: 386.6603175660902 (-0.00%)\n",
      "Position relative errors: 2.173331704525151 m, 183.5247669631027 m, 237.3326590078403 m, 243.91201873517522 m\n",
      "\n",
      "Iteration 22\n",
      "Cost function: 651.4080445345838 (-21.74%)\n",
      "Gradient norm: 131129.08972486484 (-12.98%)\n",
      "Global relative error: 211.6747002253681 (-8.00%)\n",
      "Position relative errors: 0.10595757800850837 m, 116.62710501802316 m, 120.17631954756098 m, 129.46786304390167 m\n",
      "\n",
      "Iteration 22\n",
      "L_norm = 4.381432801206737\n",
      "Grad_L_norm = 0.007054706305344031\n",
      "\n",
      "Iteration 23\n",
      "Cost function: 539.4867868672288 (-17.18%)\n",
      "Gradient norm: 115354.55871507637 (-12.03%)\n",
      "Global relative error: 199.94045872996844 (-5.54%)\n",
      "Position relative errors: 0.0895052391049044 m, 111.36877875405779 m, 129.2922263038838 m, 104.19542773714204 m\n",
      "\n",
      "Iteration 23\n",
      "L_norm = 4.381432803641484\n",
      "Grad_L_norm = 0.014069037184335192\n",
      "\n",
      "Iteration 11\n",
      "Cost function: 3169850.7008270323 (0.00%)\n",
      "Gradient norm: 0.020944339001205795 (-22.86%)\n",
      "Global relative error: 386.66031756819945 (0.00%)\n",
      "Position relative errors: 2.173331697974745 m, 183.52476697478994 m, 237.33265900745442 m, 243.91201873015896 m\n",
      "\n",
      "Iteration 24\n",
      "Cost function: 429.7210227546139 (-20.35%)\n",
      "Gradient norm: 101597.81908736938 (-11.93%)\n",
      "Global relative error: 184.11504602190325 (-7.92%)\n",
      "Position relative errors: 0.09755759648101595 m, 101.16812957804073 m, 104.73750664473181 m, 112.66497672922057 m\n",
      "\n",
      "Iteration 24\n",
      "L_norm = 4.381432801873344\n",
      "Grad_L_norm = 0.0061774528712483364\n",
      "\n",
      "Iteration 25\n",
      "Cost function: 356.93784424792835 (-16.94%)\n",
      "Gradient norm: 88590.4603493815 (-12.80%)\n",
      "Global relative error: 173.81486845598866 (-5.59%)\n",
      "Position relative errors: 0.08167622847051058 m, 96.68437327282187 m, 112.17598857537011 m, 90.9960212822426 m\n",
      "\n",
      "Iteration 25\n",
      "L_norm = 4.381432802942441\n",
      "Grad_L_norm = 0.02786868053230571\n",
      "\n",
      "Iteration 26\n",
      "Cost function: 288.75976079284715 (-19.10%)\n",
      "Gradient norm: 78924.32810854567 (-10.91%)\n",
      "Global relative error: 160.21450610104318 (-7.82%)\n",
      "Position relative errors: 0.08997060962991221 m, 87.83244168953034 m, 91.39688096655209 m, 97.983397303688 m\n",
      "\n",
      "Iteration 12\n",
      "Cost function: 3169850.7008257764 (-0.00%)\n",
      "Gradient norm: 0.042965692689081056 (105.14%)\n",
      "Global relative error: 386.66031757086466 (0.00%)\n",
      "Position relative errors: 2.1733317003986077 m, 183.52476697665915 m, 237.33265900637804 m, 243.91201873400334 m\n",
      "\n",
      "Iteration 26\n",
      "L_norm = 4.381432803846771\n",
      "Grad_L_norm = 0.011884740670684728\n",
      "\n",
      "Iteration 27\n",
      "Cost function: 240.97081903592422 (-16.55%)\n",
      "Gradient norm: 68218.28622130356 (-13.56%)\n",
      "Global relative error: 151.16886650272653 (-5.65%)\n",
      "Position relative errors: 0.07541198159985511 m, 83.96009011632079 m, 97.33137290290682 m, 79.5570447725832 m\n",
      "\n",
      "Iteration 27\n",
      "L_norm = 4.381432803863441\n",
      "Grad_L_norm = 0.030430647084708395\n",
      "\n",
      "Iteration 28\n",
      "Cost function: 197.6606863373668 (-17.97%)\n",
      "Gradient norm: 61468.13511695618 (-9.89%)\n",
      "Global relative error: 139.48404616006064 (-7.73%)\n",
      "Position relative errors: 0.08320151712796868 m, 76.31830454834434 m, 79.84570704034307 m, 85.18196401329502 m\n",
      "\n",
      "Iteration 13\n",
      "Cost function: 3169850.7008268065 (0.00%)\n",
      "Gradient norm: 0.029209865063542506 (-32.02%)\n",
      "Global relative error: 386.66031756570743 (-0.00%)\n",
      "Position relative errors: 2.1733316986547684 m, 183.52476697338855 m, 237.33265900629033 m, 243.91201872838957 m\n",
      "\n",
      "Iteration 28\n",
      "L_norm = 4.381432800056416\n",
      "Grad_L_norm = 0.07066313848046271\n",
      "\n",
      "Iteration 29\n",
      "Cost function: 165.92309212660462 (-16.06%)\n",
      "Gradient norm: 52645.73649572409 (-14.35%)\n",
      "Global relative error: 131.53771592887156 (-5.70%)\n",
      "Position relative errors: 0.0703251066059556 m, 72.93713922814335 m, 84.47210468695691 m, 69.61896060177916 m\n",
      "\n",
      "Iteration 29\n",
      "L_norm = 4.381432804820807\n",
      "Grad_L_norm = 0.025589243607614\n",
      "\n",
      "Iteration 30\n",
      "Cost function: 137.82226959530524 (-16.94%)\n",
      "Gradient norm: 47991.92387420229 (-8.84%)\n",
      "Global relative error: 121.4989259526015 (-7.63%)\n",
      "Position relative errors: 0.07722662953158128 m, 66.36739447074729 m, 69.82478863796157 m, 74.03949792298556 m\n",
      "\n",
      "Iteration 14\n",
      "Cost function: 3169850.7008279767 (0.00%)\n",
      "Gradient norm: 0.020859975670284806 (-28.59%)\n",
      "Global relative error: 386.66031756981874 (0.00%)\n",
      "Position relative errors: 2.1733316951349235 m, 183.52476697244788 m, 237.3326590068025 m, 243.9120187351478 m\n",
      "\n",
      "Iteration 30\n",
      "L_norm = 4.381432802011296\n",
      "Grad_L_norm = 0.029491841857284297\n",
      "\n",
      "Iteration 31\n",
      "Cost function: 116.48183230885604 (-15.48%)\n",
      "Gradient norm: 40699.37182902796 (-15.20%)\n",
      "Global relative error: 114.51702015446332 (-5.75%)\n",
      "Position relative errors: 0.06612483729020704 m, 63.389505877367476 m, 73.34168121066828 m, 60.96645986846622 m\n",
      "\n",
      "Iteration 31\n",
      "L_norm = 4.381432802331152\n",
      "Grad_L_norm = 0.005999832649849107\n",
      "\n",
      "Iteration 32\n",
      "Cost function: 97.88338035869825 (-15.97%)\n",
      "Gradient norm: 37560.32078687454 (-7.71%)\n",
      "Global relative error: 105.89001274886027 (-7.53%)\n",
      "Position relative errors: 0.07199690216209635 m, 57.758734463468286 m, 61.115745812073776 m, 64.35433928559412 m\n",
      "\n",
      "Iteration 32\n",
      "L_norm = 4.381432803193878\n",
      "Grad_L_norm = 0.01622906193341922\n",
      "\n",
      "Iteration 15\n",
      "Cost function: 3169850.700825727 (-0.00%)\n",
      "Gradient norm: 0.03537219722799337 (69.57%)\n",
      "Global relative error: 386.6603175738035 (0.00%)\n",
      "Position relative errors: 2.173331702076002 m, 183.5247669806914 m, 237.33265900869904 m, 243.91201873335478 m\n",
      "\n",
      "Iteration 33\n",
      "Cost function: 83.34786268110369 (-14.85%)\n",
      "Gradient norm: 31507.161704572958 (-16.12%)\n",
      "Global relative error: 99.75489612062495 (-5.79%)\n",
      "Position relative errors: 0.0625982816698484 m, 55.119554007473155 m, 63.71207948715511 m, 53.4194624657961 m\n",
      "\n",
      "Iteration 33\n",
      "L_norm = 4.381432801586983\n",
      "Grad_L_norm = 0.010086851459394298\n",
      "\n",
      "Iteration 34\n",
      "Cost function: 70.80708107658323 (-15.05%)\n",
      "Gradient norm: 29464.62623964917 (-6.48%)\n",
      "Global relative error: 92.33698994856822 (-7.44%)\n",
      "Position relative errors: 0.06744719190144413 m, 50.303523170685146 m, 53.53427532854489 m, 55.944167349419914 m\n",
      "\n",
      "Iteration 34\n",
      "L_norm = 4.3814328049810225\n",
      "Grad_L_norm = 0.03409982474134028\n",
      "\n",
      "Iteration 16\n",
      "Cost function: 3169850.7008260125 (0.00%)\n",
      "Gradient norm: 0.050524175575969776 (42.84%)\n",
      "Global relative error: 386.6603175684263 (-0.00%)\n",
      "Position relative errors: 2.173331705885869 m, 183.52476696854865 m, 237.33265900532618 m, 243.91201873721502 m\n",
      "\n",
      "Iteration 35\n",
      "Cost function: 60.776630301864486 (-14.17%)\n",
      "Gradient norm: 24416.51419261071 (-17.13%)\n",
      "Global relative error: 86.94580208471355 (-5.84%)\n",
      "Position relative errors: 0.05959293961016474 m, 47.95482706988609 m, 55.38211044330131 m, 46.82652745213829 m\n",
      "\n",
      "Iteration 35\n",
      "L_norm = 4.38143280495458\n",
      "Grad_L_norm = 0.018864083067447992\n",
      "\n",
      "Iteration 36\n",
      "Cost function: 52.17206285237719 (-14.16%)\n",
      "Gradient norm: 23166.483773442964 (-5.12%)\n",
      "Global relative error: 80.5624794817946 (-7.34%)\n",
      "Position relative errors: 0.06350531272152053 m, 43.840559429979805 m, 46.92457376204193 m, 48.645627200899256 m\n",
      "\n",
      "Iteration 36\n",
      "L_norm = 4.381432803343599\n",
      "Grad_L_norm = 0.007471134999153399\n",
      "\n",
      "Iteration 17\n",
      "Cost function: 3169850.700826657 (0.00%)\n",
      "Gradient norm: 0.043442550447391655 (-14.02%)\n",
      "Global relative error: 386.66031756252534 (-0.00%)\n",
      "Position relative errors: 2.1733317013265188 m, 183.5247669683859 m, 237.33265900646222 m, 243.91201872691823 m\n",
      "\n",
      "Iteration 37\n",
      "Cost function: 45.16042989165621 (-13.44%)\n",
      "Gradient norm: 18936.027723435796 (-18.26%)\n",
      "Global relative error: 75.82510858754215 (-5.88%)\n",
      "Position relative errors: 0.05700077877904596 m, 41.74532959988663 m, 48.17544637136119 m, 41.05966787198244 m\n",
      "\n",
      "Iteration 37\n",
      "L_norm = 4.38143280131098\n",
      "Grad_L_norm = 0.0033066587189246447\n",
      "\n",
      "Iteration 38\n",
      "Cost function: 39.16049106686164 (-13.29%)\n",
      "Gradient norm: 18255.702986390752 (-3.59%)\n",
      "Global relative error: 70.32673252783032 (-7.25%)\n",
      "Position relative errors: 0.06009876906447999 m, 38.23219872154648 m, 41.1546138959942 m, 42.31360369496717 m\n",
      "\n",
      "Iteration 38\n",
      "L_norm = 4.381432801447458\n",
      "Grad_L_norm = 0.01213095108219918\n",
      "\n",
      "Iteration 18\n",
      "Cost function: 3169850.700828863 (0.00%)\n",
      "Gradient norm: 0.02909314540688351 (-33.03%)\n",
      "Global relative error: 386.66031756907034 (0.00%)\n",
      "Position relative errors: 2.1733316998868446 m, 183.52476697485042 m, 237.33265900695403 m, 243.91201873196385 m\n",
      "\n",
      "Iteration 39\n",
      "Cost function: 34.19722732857415 (-12.67%)\n",
      "Gradient norm: 14693.593677033661 (-19.51%)\n",
      "Global relative error: 66.1641224819102 (-5.92%)\n",
      "Position relative errors: 0.05474491680161516 m, 36.36102112778215 m, 41.93842462917362 m, 36.01016131822914 m\n",
      "\n",
      "Iteration 39\n",
      "L_norm = 4.381432802741327\n",
      "Grad_L_norm = 0.03656428869037096\n",
      "\n",
      "Iteration 40\n",
      "Cost function: 29.950887433223286 (-12.42%)\n",
      "Gradient norm: 14418.706084588008 (-1.87%)\n",
      "Global relative error: 61.42280209144286 (-7.17%)\n",
      "Position relative errors: 0.0571589686429935 m, 33.360826045277165 m, 36.11215546668711 m, 36.820154550841515 m\n",
      "\n",
      "Iteration 40\n",
      "L_norm = 4.381432804509386\n",
      "Grad_L_norm = 0.038259024867012006\n",
      "\n",
      "Iteration 19\n",
      "Cost function: 3169850.7008266496 (-0.00%)\n",
      "Gradient norm: 0.00421196592687673 (-85.52%)\n",
      "Global relative error: 386.66031757505647 (0.00%)\n",
      "Position relative errors: 2.1733317010805138 m, 183.52476697244845 m, 237.33265900816335 m, 243.91201874207331 m\n",
      "\n",
      "Iteration 41\n",
      "Cost function: 26.395315342117666 (-11.87%)\n",
      "Gradient norm: 11406.001289476322 (-20.89%)\n",
      "Global relative error: 57.765518760533126 (-5.95%)\n",
      "Position relative errors: 0.052769608945375086 m, 31.689462192141637 m, 36.53775037217781 m, 31.585159528905493 m\n",
      "\n",
      "Iteration 41\n",
      "L_norm = 4.3814328014798205\n",
      "Grad_L_norm = 0.022201958028882175\n",
      "\n",
      "Iteration 42\n",
      "Cost function: 23.34918959552905 (-11.54%)\n",
      "Gradient norm: 11414.948562538884 (0.08%)\n",
      "Global relative error: 53.672192646464744 (-7.09%)\n",
      "Position relative errors: 0.05462342555214402 m, 29.125822813553913 m, 31.701416900554918 m, 32.0531908018844 m\n",
      "\n",
      "Iteration 42\n",
      "L_norm = 4.381432801887896\n",
      "Grad_L_norm = 0.04607949990535341\n",
      "\n",
      "Iteration 20\n",
      "Cost function: 3169850.700826521 (-0.00%)\n",
      "Gradient norm: 0.022020017536894653 (422.80%)\n",
      "Global relative error: 386.66031756994937 (-0.00%)\n",
      "Position relative errors: 2.1733316998940344 m, 183.5247669743766 m, 237.33265900857586 m, 243.91201873213572 m\n",
      "\n",
      "Iteration 43\n",
      "Cost function: 20.77342269353408 (-11.03%)\n",
      "Gradient norm: 8856.688071784467 (-22.41%)\n",
      "Global relative error: 50.4592000283792 (-5.99%)\n",
      "Position relative errors: 0.05103312056414457 m, 27.633623464504147 m, 31.85821009418214 m, 27.70496140300826 m\n",
      "\n",
      "Iteration 43\n",
      "L_norm = 4.381432804484481\n",
      "Grad_L_norm = 0.01007886691026211\n",
      "\n",
      "Iteration 44\n",
      "Cost function: 18.56162387961794 (-10.65%)\n",
      "Gradient norm: 9059.293446590667 (2.29%)\n",
      "Global relative error: 46.92098911899036 (-7.01%)\n",
      "Position relative errors: 0.052436526245812486 m, 25.440985646134163 m, 27.840333178980373 m, 27.91501206633555 m\n",
      "\n",
      "Iteration 44\n",
      "L_norm = 4.381432803555282\n",
      "Grad_L_norm = 0.012089516129941103\n",
      "\n",
      "Iteration 21\n",
      "Cost function: 3169850.700825614 (-0.00%)\n",
      "Gradient norm: 0.05054939587198751 (129.56%)\n",
      "Global relative error: 386.66031757272515 (0.00%)\n",
      "Position relative errors: 2.173331700537076 m, 183.52476697674993 m, 237.33265900823017 m, 243.9120187350809 m\n",
      "\n",
      "Iteration 45\n",
      "Cost function: 16.676437141346177 (-10.16%)\n",
      "Gradient norm: 6879.409049219647 (-24.06%)\n",
      "Global relative error: 44.09859965806512 (-6.02%)\n",
      "Position relative errors: 0.04950300596310514 m, 24.10988236236549 m, 27.80048187809618 m, 24.30082878805827 m\n",
      "\n",
      "Iteration 45\n",
      "L_norm = 4.381432803437423\n",
      "Grad_L_norm = 0.010691909575491685\n",
      "\n",
      "Iteration 46\n",
      "Cost function: 15.053113314261637 (-9.73%)\n",
      "Gradient norm: 7208.800101516925 (4.79%)\n",
      "Global relative error: 41.036453636445856 (-6.94%)\n",
      "Position relative errors: 0.0505495807307064 m, 22.232345769018643 m, 24.458315509168703 m, 24.320794591893662 m\n",
      "\n",
      "Iteration 46\n",
      "L_norm = 4.38143280364094\n",
      "Grad_L_norm = 0.012128252387424057\n",
      "\n",
      "Iteration 22\n",
      "Cost function: 3169850.7008268023 (0.00%)\n",
      "Gradient norm: 0.04438244704266247 (-12.20%)\n",
      "Global relative error: 386.6603175684681 (-0.00%)\n",
      "Position relative errors: 2.1733317063258846 m, 183.52476697577944 m, 237.33265900699152 m, 243.91201873021637 m\n",
      "\n",
      "Iteration 47\n",
      "Cost function: 13.660577051590591 (-9.25%)\n",
      "Gradient norm: 5346.068698214657 (-25.84%)\n",
      "Global relative error: 38.557424579300026 (-6.04%)\n",
      "Position relative errors: 0.04815308190861258 m, 21.046222815297437 m, 24.279099574504734 m, 21.313236987073562 m\n",
      "\n",
      "Iteration 47\n",
      "L_norm = 4.38143280076292\n",
      "Grad_L_norm = 0.0038655126118461985\n",
      "\n",
      "Iteration 48\n",
      "Cost function: 12.45793435160823 (-8.80%)\n",
      "Gradient norm: 5752.772651551366 (7.61%)\n",
      "Global relative error: 35.90406207502048 (-6.88%)\n",
      "Position relative errors: 0.04892038882100177 m, 19.436332657112725 m, 21.494428281436495 m, 21.197108119783127 m\n",
      "\n",
      "Iteration 48\n",
      "L_norm = 4.381432801145127\n",
      "Grad_L_norm = 0.014108778134789548\n",
      "\n",
      "Iteration 23\n",
      "Cost function: 3169850.7008248186 (-0.00%)\n",
      "Gradient norm: 0.028273662612007547 (-36.30%)\n",
      "Global relative error: 386.66031756831813 (-0.00%)\n",
      "Position relative errors: 2.1733316980568786 m, 183.52476697288685 m, 237.33265900523415 m, 243.91201873393865 m\n",
      "\n",
      "Iteration 49\n",
      "Cost function: 11.42088769558842 (-8.32%)\n",
      "Gradient norm: 4157.675827371629 (-27.73%)\n",
      "Global relative error: 33.726814224043196 (-6.06%)\n",
      "Position relative errors: 0.046961498948728 m, 18.38064045894441 m, 21.220602809042244 m, 18.690466144462576 m\n",
      "\n",
      "Iteration 49\n",
      "L_norm = 4.38143280171912\n",
      "Grad_L_norm = 0.016587476589606458\n",
      "\n",
      "Iteration 50\n",
      "Cost function: 10.522676112517475 (-7.86%)\n",
      "Gradient norm: 4605.263106609366 (10.77%)\n",
      "Global relative error: 31.424941951584874 (-6.83%)\n",
      "Position relative errors: 0.04751259002555376 m, 16.998229110549612 m, 18.8959041022224 m, 18.48051433754823 m\n",
      "\n",
      "Iteration 50\n",
      "L_norm = 4.381432802996059\n",
      "Grad_L_norm = 0.03624831522783876\n",
      "\n",
      "Iteration 24\n",
      "Cost function: 3169850.7008267473 (0.00%)\n",
      "Gradient norm: 0.0036871093704303067 (-86.96%)\n",
      "Global relative error: 386.6603175647266 (-0.00%)\n",
      "Position relative errors: 2.1733316962560965 m, 183.52476697020603 m, 237.33265900724274 m, 243.91201872832391 m\n",
      "\n",
      "Iteration 51\n",
      "Cost function: 9.744874467810812 (-7.39%)\n",
      "Gradient norm: 3237.536088569098 (-29.70%)\n",
      "Global relative error: 29.512881144712324 (-6.08%)\n",
      "Position relative errors: 0.045909622056167707 m, 16.05974564181248 m, 18.56188545213743 m, 16.387457249050275 m\n",
      "\n",
      "Iteration 51\n",
      "L_norm = 4.381432803062762\n",
      "Grad_L_norm = 0.04488162776799157\n",
      "\n",
      "Iteration 52\n",
      "Cost function: 9.069396935773655 (-6.93%)\n",
      "Gradient norm: 3699.3878609202006 (14.27%)\n",
      "Global relative error: 27.51366800454481 (-6.77%)\n",
      "Position relative errors: 0.04629498833313944 m, 14.870871089694841 m, 16.616928375174144 m, 16.116277923290944 m\n",
      "\n",
      "Iteration 52\n",
      "L_norm = 4.38143280100667\n",
      "Grad_L_norm = 0.014470628486009413\n",
      "\n",
      "Iteration 25\n",
      "Cost function: 3169850.7008269858 (0.00%)\n",
      "Gradient norm: 0.010937446612132314 (196.64%)\n",
      "Global relative error: 386.6603175716035 (0.00%)\n",
      "Position relative errors: 2.173331699327399 m, 183.52476697967086 m, 237.33265900699573 m, 243.91201873231705 m\n",
      "\n",
      "Iteration 53\n",
      "Cost function: 8.48247684707402 (-6.47%)\n",
      "Gradient norm: 2526.0911444592416 (-31.72%)\n",
      "Global relative error: 25.834592807548383 (-6.10%)\n",
      "Position relative errors: 0.044981230217415624 m, 14.037549364771058 m, 16.24874100869951 m, 14.364872900137488 m\n",
      "\n",
      "Iteration 53\n",
      "L_norm = 4.381432801488043\n",
      "Grad_L_norm = 0.035982281535295126\n",
      "\n",
      "Iteration 54\n",
      "Cost function: 7.971545489759733 (-6.02%)\n",
      "Gradient norm: 2982.9897491307906 (18.09%)\n",
      "Global relative error: 24.096371265651904 (-6.73%)\n",
      "Position relative errors: 0.04524086227914181 m, 13.013551154682611 m, 14.617637689771984 m, 14.057205171518431 m\n",
      "\n",
      "Iteration 54\n",
      "L_norm = 4.381432804833877\n",
      "Grad_L_norm = 0.03338231678158917\n",
      "\n",
      "Iteration 26\n",
      "Cost function: 3169850.700826061 (-0.00%)\n",
      "Gradient norm: 0.04853046498574636 (343.71%)\n",
      "Global relative error: 386.6603175686959 (-0.00%)\n",
      "Position relative errors: 2.17333170133633 m, 183.52476697193092 m, 237.33265900843188 m, 243.9120187321162 m\n",
      "\n",
      "Iteration 55\n",
      "Cost function: 7.5263778668908605 (-5.58%)\n",
      "Gradient norm: 1976.9982194377008 (-33.72%)\n",
      "Global relative error: 22.62195369337642 (-6.12%)\n",
      "Position relative errors: 0.04416208535691723 m, 12.274414974638422 m, 14.234594398963159 m, 12.58831723725537 m\n",
      "\n",
      "Iteration 55\n",
      "L_norm = 4.381432801012096\n",
      "Grad_L_norm = 0.0035828868686819046\n",
      "\n",
      "Iteration 56\n",
      "Cost function: 7.138033905969785 (-5.16%)\n",
      "Gradient norm: 2415.3175703204943 (22.17%)\n",
      "Global relative error: 21.109119710552026 (-6.69%)\n",
      "Position relative errors: 0.04432735333380565 m, 11.391091190034443 m, 12.863287404208318 m, 12.262613637212633 m\n",
      "\n",
      "Iteration 56\n",
      "L_norm = 4.381432800439938\n",
      "Grad_L_norm = 0.02784436860307367\n",
      "\n",
      "Iteration 27\n",
      "Cost function: 3169850.700825719 (-0.00%)\n",
      "Gradient norm: 0.052768538073300224 (8.73%)\n",
      "Global relative error: 386.6603175682315 (-0.00%)\n",
      "Position relative errors: 2.1733317038597924 m, 183.52476696716434 m, 237.33265900518106 m, 243.91201873810698 m\n",
      "\n",
      "Iteration 57\n",
      "Cost function: 6.798925029339207 (-4.75%)\n",
      "Gradient norm: 1554.1151184083808 (-35.66%)\n",
      "Global relative error: 19.814448284086634 (-6.13%)\n",
      "Position relative errors: 0.043439604055855334 m, 10.736156349095246 m, 12.47940498140829 m, 11.027680659061188 m\n",
      "\n",
      "Iteration 57\n",
      "L_norm = 4.381432802140513\n",
      "Grad_L_norm = 0.012722604504810697\n",
      "\n",
      "Iteration 58\n",
      "Cost function: 6.502571392487337 (-4.36%)\n",
      "Gradient norm: 1964.497308462613 (26.41%)\n",
      "Global relative error: 18.496532920988145 (-6.65%)\n",
      "Position relative errors: 0.04353491759941524 m, 9.973057476752267 m, 11.323553566048988 m, 10.69742831955585 m\n",
      "\n",
      "Iteration 58\n",
      "L_norm = 4.381432801076827\n",
      "Grad_L_norm = 0.021916331820786755\n",
      "\n",
      "Iteration 28\n",
      "Cost function: 3169850.7008275227 (0.00%)\n",
      "Gradient norm: 0.04737941653789366 (-10.21%)\n",
      "Global relative error: 386.66031756650676 (-0.00%)\n",
      "Position relative errors: 2.1733317022757106 m, 183.52476697264504 m, 237.33265900603595 m, 243.91201873043144 m\n",
      "\n",
      "Iteration 59\n",
      "Cost function: 6.243328594393261 (-3.99%)\n",
      "Gradient norm: 1229.2122398493086 (-37.43%)\n",
      "Global relative error: 17.359709207948725 (-6.15%)\n",
      "Position relative errors: 0.04280260597325791 m, 9.393264492938158 m, 10.948723058026678 m, 9.656583992669889 m\n",
      "\n",
      "Iteration 59\n",
      "L_norm = 4.3814328042369\n",
      "Grad_L_norm = 0.018120703955602484\n",
      "\n",
      "Iteration 60\n",
      "Cost function: 6.016429231351393 (-3.63%)\n",
      "Gradient norm: 1605.566872386663 (30.62%)\n",
      "Global relative error: 16.2105963252131 (-6.62%)\n",
      "Position relative errors: 0.04284683732220217 m, 8.733093083523338 m, 9.971942881914774 m, 9.331395562235853 m\n",
      "\n",
      "Iteration 60\n",
      "L_norm = 4.381432805699156\n",
      "Grad_L_norm = 0.031273433963930855\n",
      "\n",
      "Iteration 61\n",
      "Cost function: 5.817658916050061 (-3.30%)\n",
      "Gradient norm: 980.1569160981649 (-38.95%)\n",
      "Global relative error: 15.212378428835962 (-6.16%)\n",
      "Position relative errors: 0.04224118265260574 m, 8.220245396101094 m, 9.61288169635806 m, 8.451902968540116 m\n",
      "\n",
      "Iteration 29\n",
      "Cost function: 3169850.700825997 (-0.00%)\n",
      "Gradient norm: 0.03853549200310038 (-18.67%)\n",
      "Global relative error: 386.66031757229064 (0.00%)\n",
      "Position relative errors: 2.1733317061369046 m, 183.52476697640577 m, 237.33265900852032 m, 243.91201873431882 m\n",
      "\n",
      "Iteration 61\n",
      "L_norm = 4.381432800426516\n",
      "Grad_L_norm = 0.017311530824833676\n",
      "\n",
      "Iteration 62\n",
      "Cost function: 5.6434688564376145 (-2.99%)\n",
      "Gradient norm: 1318.9574034081488 (34.57%)\n",
      "Global relative error: 14.20964652543668 (-6.59%)\n",
      "Position relative errors: 0.04224879321933685 m, 7.648349961792769 m, 8.785290259657945 m, 8.138403635404623 m\n",
      "\n",
      "Iteration 62\n",
      "L_norm = 4.381432803729316\n",
      "Grad_L_norm = 0.010819742621962428\n",
      "\n",
      "Iteration 63\n",
      "Cost function: 5.490698005443983 (-2.71%)\n",
      "Gradient norm: 789.57807548685 (-40.14%)\n",
      "Global relative error: 13.333133469866135 (-6.17%)\n",
      "Position relative errors: 0.04174653227478801 m, 7.1950540453695995 m, 8.446306346416375 m, 7.393358433196638 m\n",
      "\n",
      "Iteration 30\n",
      "Cost function: 3169850.7008264046 (0.00%)\n",
      "Gradient norm: 0.05018607970637138 (30.23%)\n",
      "Global relative error: 386.6603175687775 (-0.00%)\n",
      "Position relative errors: 2.1733317035038615 m, 183.52476696534848 m, 237.33265900876606 m, 243.91201873685378 m\n",
      "\n",
      "Iteration 63\n",
      "L_norm = 4.381432803867225\n",
      "Grad_L_norm = 0.032423956077500246\n",
      "\n",
      "Iteration 64\n",
      "Cost function: 5.356680488019091 (-2.44%)\n",
      "Gradient norm: 1089.316703101577 (37.96%)\n",
      "Global relative error: 12.457501830106352 (-6.57%)\n",
      "Position relative errors: 0.041728531561304565 m, 6.6990039434569315 m, 7.743328127442664 m, 7.095898045673765 m\n",
      "\n",
      "Iteration 64\n",
      "L_norm = 4.38143280127918\n",
      "Grad_L_norm = 0.06528273580855858\n",
      "\n",
      "Iteration 65\n",
      "Cost function: 5.239034180853034 (-2.20%)\n",
      "Gradient norm: 643.7909700484543 (-40.90%)\n",
      "Global relative error: 11.687854440905378 (-6.18%)\n",
      "Position relative errors: 0.041310835089999484 m, 6.298610289711283 m, 7.426926315823443 m, 6.463161752146733 m\n",
      "\n",
      "Iteration 31\n",
      "Cost function: 3169850.7008265085 (0.00%)\n",
      "Gradient norm: 0.012023244788710495 (-76.04%)\n",
      "Global relative error: 386.66031756864624 (-0.00%)\n",
      "Position relative errors: 2.173331702948966 m, 183.5247669725098 m, 237.332659003772 m, 243.91201873612155 m\n",
      "\n",
      "Iteration 65\n",
      "L_norm = 4.381432801931287\n",
      "Grad_L_norm = 0.08932396565324865\n",
      "\n",
      "Iteration 66\n",
      "Cost function: 5.135742213151913 (-1.97%)\n",
      "Gradient norm: 904.6054132545274 (40.51%)\n",
      "Global relative error: 10.92271711665867 (-6.55%)\n",
      "Position relative errors: 0.0412755240714642 m, 5.867840385693573 m, 6.828315620846998 m, 6.1843800163955605 m\n",
      "\n",
      "Iteration 66\n",
      "L_norm = 4.381432803580756\n",
      "Grad_L_norm = 0.03220564906087052\n",
      "\n",
      "Iteration 67\n",
      "Cost function: 5.045001351774991 (-1.77%)\n",
      "Gradient norm: 532.0322489942932 (-41.19%)\n",
      "Global relative error: 10.246910964955251 (-6.19%)\n",
      "Position relative errors: 0.04092715351830824 m, 5.514385354236553 m, 6.535673385658149 m, 5.64570622883412 m\n",
      "\n",
      "Iteration 32\n",
      "Cost function: 3169850.7008270663 (0.00%)\n",
      "Gradient norm: 0.0543174502546902 (351.77%)\n",
      "Global relative error: 386.6603175673012 (-0.00%)\n",
      "Position relative errors: 2.173331705914054 m, 183.5247669664874 m, 237.33265900798358 m, 243.91201873439644 m\n",
      "\n",
      "Iteration 67\n",
      "L_norm = 4.381432803038285\n",
      "Grad_L_norm = 0.029140727097652242\n",
      "\n",
      "Iteration 68\n",
      "Cost function: 4.96527728032684 (-1.58%)\n",
      "Gradient norm: 755.369114013808 (41.98%)\n",
      "Global relative error: 9.577944084820901 (-6.53%)\n",
      "Position relative errors: 0.04088076637146476 m, 5.139899052952359 m, 6.0247177713912246 m, 5.3869769654403825 m\n",
      "\n",
      "Iteration 68\n",
      "L_norm = 4.381432803723293\n",
      "Grad_L_norm = 0.010422777142066363\n",
      "\n",
      "Iteration 69\n",
      "Cost function: 4.895199380454714 (-1.41%)\n",
      "Gradient norm: 445.86976393417615 (-40.97%)\n",
      "Global relative error: 8.98455124893759 (-6.20%)\n",
      "Position relative errors: 0.04058934570377404 m, 4.828047802878733 m, 5.75605497580352 m, 4.927298416434617 m\n",
      "\n",
      "Iteration 33\n",
      "Cost function: 3169850.7008267925 (-0.00%)\n",
      "Gradient norm: 0.019293380078036503 (-64.48%)\n",
      "Global relative error: 386.66031757009574 (0.00%)\n",
      "Position relative errors: 2.173331699123456 m, 183.52476696951643 m, 237.33265900744644 m, 243.9120187371304 m\n",
      "\n",
      "Iteration 69\n",
      "L_norm = 4.381432804606581\n",
      "Grad_L_norm = 0.0038082641075787506\n",
      "\n",
      "Iteration 70\n",
      "Cost function: 4.833595417240101 (-1.26%)\n",
      "Gradient norm: 634.206580332261 (42.24%)\n",
      "Global relative error: 8.399381991046091 (-6.51%)\n",
      "Position relative errors: 0.04053647046383968 m, 4.50216997321625 m, 5.318927201146221 m, 4.689075288564405 m\n",
      "\n",
      "Iteration 70\n",
      "L_norm = 4.3814328029252065\n",
      "Grad_L_norm = 0.005353397284286514\n",
      "\n",
      "Iteration 71\n",
      "Cost function: 4.779419799814184 (-1.12%)\n",
      "Gradient norm: 378.7726555268379 (-40.28%)\n",
      "Global relative error: 7.878378310167942 (-6.20%)\n",
      "Position relative errors: 0.040291979439112044 m, 4.227161254654487 m, 5.073790538623623 m, 4.295923163901731 m\n",
      "\n",
      "Iteration 34\n",
      "Cost function: 3169850.700827297 (0.00%)\n",
      "Gradient norm: 0.05687001058672121 (194.76%)\n",
      "Global relative error: 386.66031757002924 (-0.00%)\n",
      "Position relative errors: 2.173331695367801 m, 183.5247669818277 m, 237.3326590056031 m, 243.91201872958894 m\n",
      "\n",
      "Iteration 71\n",
      "L_norm = 4.381432804323728\n",
      "Grad_L_norm = 0.002633946509945992\n",
      "\n",
      "Iteration 72\n",
      "Cost function: 4.731773918571779 (-1.00%)\n",
      "Gradient norm: 535.3097065424587 (41.33%)\n",
      "Global relative error: 7.366305026633756 (-6.50%)\n",
      "Position relative errors: 0.040235970619117524 m, 3.9433315283593786 m, 4.699022213325482 m, 4.078006504852034 m\n",
      "\n",
      "Iteration 72\n",
      "L_norm = 4.381432802886165\n",
      "Grad_L_norm = 0.016940514610673238\n",
      "\n",
      "Iteration 73\n",
      "Cost function: 4.689857629684367 (-0.89%)\n",
      "Gradient norm: 325.75748883342743 (-39.15%)\n",
      "Global relative error: 6.908900196150669 (-6.21%)\n",
      "Position relative errors: 0.04003025151379403 m, 3.7009250532037687 m, 4.476501745243454 m, 3.7410383260400915 m\n",
      "\n",
      "Iteration 73\n",
      "L_norm = 4.3814328036815375\n",
      "Grad_L_norm = 0.013553387439104144\n",
      "\n",
      "Iteration 35\n",
      "Cost function: 3169850.7008278067 (0.00%)\n",
      "Gradient norm: 0.026067081649613397 (-54.16%)\n",
      "Global relative error: 386.6603175712261 (0.00%)\n",
      "Position relative errors: 2.17333169691342 m, 183.52476696949523 m, 237.33265900466148 m, 243.91201874166782 m\n",
      "\n",
      "Iteration 74\n",
      "Cost function: 4.652980270552003 (-0.79%)\n",
      "Gradient norm: 454.1210877613415 (39.40%)\n",
      "Global relative error: 6.460655730924192 (-6.49%)\n",
      "Position relative errors: 0.039973509546145196 m, 3.453525845850216 m, 4.154555960858352 m, 3.5427789730969543 m\n",
      "\n",
      "Iteration 74\n",
      "L_norm = 4.38143280422126\n",
      "Grad_L_norm = 0.011791728661242399\n",
      "\n",
      "Iteration 75\n",
      "Cost function: 4.62052790230779 (-0.70%)\n",
      "Gradient norm: 283.1040441380803 (-37.66%)\n",
      "Global relative error: 6.059143639336355 (-6.21%)\n",
      "Position relative errors: 0.03979990467048274 m, 3.2399525321581244 m, 3.9534480426334997 m, 3.2533951812360775 m\n",
      "\n",
      "Iteration 75\n",
      "L_norm = 4.381432803990361\n",
      "Grad_L_norm = 0.012324356216034874\n",
      "\n",
      "Iteration 36\n",
      "Cost function: 3169850.700826849 (-0.00%)\n",
      "Gradient norm: 0.024953321208892192 (-4.27%)\n",
      "Global relative error: 386.66031757119646 (-0.00%)\n",
      "Position relative errors: 2.1733316950521298 m, 183.52476697772016 m, 237.33265900879329 m, 243.9120187314284 m\n",
      "\n",
      "Iteration 76\n",
      "Cost function: 4.59196859639086 (-0.62%)\n",
      "Gradient norm: 387.0712636398852 (36.72%)\n",
      "Global relative error: 5.666694612367479 (-6.48%)\n",
      "Position relative errors: 0.03974411860900758 m, 3.024165035730122 m, 3.676372598630857 m, 3.0738488092656726 m\n",
      "\n",
      "Iteration 76\n",
      "L_norm = 4.38143280274828\n",
      "Grad_L_norm = 0.008199432272822672\n",
      "\n",
      "Iteration 77\n",
      "Cost function: 4.566830250100945 (-0.55%)\n",
      "Gradient norm: 248.09865398682751 (-35.90%)\n",
      "Global relative error: 5.314321734703728 (-6.22%)\n",
      "Position relative errors: 0.039597200017597416 m, 2.836080722392306 m, 3.4953010241265425 m, 2.8248812409029753 m\n",
      "\n",
      "Iteration 77\n",
      "L_norm = 4.381432801866115\n",
      "Grad_L_norm = 0.006376394690382173\n",
      "\n",
      "Iteration 37\n",
      "Cost function: 3169850.7008275962 (0.00%)\n",
      "Gradient norm: 0.01121175152689971 (-55.07%)\n",
      "Global relative error: 386.6603175687655 (-0.00%)\n",
      "Position relative errors: 2.173331692154901 m, 183.52476697471872 m, 237.33265900428356 m, 243.91201873424708 m\n",
      "\n",
      "Iteration 78\n",
      "Cost function: 4.544702506808754 (-0.48%)\n",
      "Gradient norm: 331.36241006449177 (33.56%)\n",
      "Global relative error: 4.970698026625468 (-6.47%)\n",
      "Position relative errors: 0.03954350821116469 m, 2.647764592874555 m, 3.2564465327018857 m, 2.6629240629858137 m\n",
      "\n",
      "Iteration 78\n",
      "L_norm = 4.381432802164184\n",
      "Grad_L_norm = 0.025818844049707416\n",
      "\n",
      "Iteration 79\n",
      "Cost function: 4.525221669795313 (-0.43%)\n",
      "Gradient norm: 218.79556634438111 (-33.97%)\n",
      "Global relative error: 4.661547687865243 (-6.22%)\n",
      "Position relative errors: 0.03941883266095082 m, 2.4822066837317545 m, 3.093951387878155 m, 2.4483830997660783 m\n",
      "\n",
      "Iteration 79\n",
      "L_norm = 4.381432806411034\n",
      "Grad_L_norm = 0.08338076815322218\n",
      "\n",
      "Iteration 38\n",
      "Cost function: 3169850.700829078 (0.00%)\n",
      "Gradient norm: 0.04882261779979516 (335.46%)\n",
      "Global relative error: 386.6603175728668 (0.00%)\n",
      "Position relative errors: 2.1733317012188027 m, 183.52476698195818 m, 237.3326590061858 m, 243.91201873336982 m\n",
      "\n",
      "Iteration 80\n",
      "Cost function: 4.508070767804066 (-0.38%)\n",
      "Gradient norm: 284.7915348672287 (30.16%)\n",
      "Global relative error: 4.360697300745577 (-6.45%)\n",
      "Position relative errors: 0.03936796504374858 m, 2.3177993475340943 m, 2.887742115431547 m, 2.302797363204753 m\n",
      "\n",
      "Iteration 80\n",
      "L_norm = 4.381432805671847\n",
      "Grad_L_norm = 0.07374392788447577\n",
      "\n",
      "Iteration 81\n",
      "Cost function: 4.492969210525932 (-0.33%)\n",
      "Gradient norm: 193.82192564928837 (-31.94%)\n",
      "Global relative error: 4.089588210168738 (-6.22%)\n",
      "Position relative errors: 0.039261879222738064 m, 2.1721475220979882 m, 2.742343429061583 m, 2.1176665903189154 m\n",
      "\n",
      "Iteration 81\n",
      "L_norm = 4.381432803501348\n",
      "Grad_L_norm = 0.03414940512552436\n",
      "\n",
      "Iteration 39\n",
      "Cost function: 3169850.7008258197 (-0.00%)\n",
      "Gradient norm: 0.04381362098233998 (-10.26%)\n",
      "Global relative error: 386.660317577091 (0.00%)\n",
      "Position relative errors: 2.1733317048465084 m, 183.52476697783297 m, 237.33265900640728 m, 243.91201874292236 m\n",
      "\n",
      "Iteration 82\n",
      "Cost function: 4.47967190133922 (-0.30%)\n",
      "Gradient norm: 245.63788791506724 (26.73%)\n",
      "Global relative error: 3.826253550121133 (-6.44%)\n",
      "Position relative errors: 0.03921427998869333 m, 2.0285795205707804 m, 2.564090739418313 m, 1.9872032820615961 m\n",
      "\n",
      "Iteration 82\n",
      "L_norm = 4.381432803700338\n",
      "Grad_L_norm = 0.020689107115314694\n",
      "\n",
      "Iteration 83\n",
      "Cost function: 4.467962091694543 (-0.26%)\n",
      "Gradient norm: 172.2151918189337 (-29.89%)\n",
      "Global relative error: 3.5886506377140543 (-6.21%)\n",
      "Position relative errors: 0.03912376867959945 m, 1.9005195438746003 m, 2.4343331775497106 m, 1.8272726997929298 m\n",
      "\n",
      "Iteration 83\n",
      "L_norm = 4.381432802748138\n",
      "Grad_L_norm = 0.002377154928286863\n",
      "\n",
      "Iteration 40\n",
      "Cost function: 3169850.700826059 (0.00%)\n",
      "Gradient norm: 0.0101540244502976 (-76.82%)\n",
      "Global relative error: 386.6603175677445 (-0.00%)\n",
      "Position relative errors: 2.173331702367223 m, 183.52476696942853 m, 237.33265900470306 m, 243.91201873610984 m\n",
      "\n",
      "Iteration 84\n",
      "Cost function: 4.457650136662839 (-0.23%)\n",
      "Gradient norm: 212.5320397332302 (23.41%)\n",
      "Global relative error: 3.358262753700839 (-6.42%)\n",
      "Position relative errors: 0.039079652333611825 m, 1.7751436407151462 m, 2.280083157023463 m, 1.7106967153622992 m\n",
      "\n",
      "Iteration 84\n",
      "L_norm = 4.381432802846731\n",
      "Grad_L_norm = 0.005795486390727963\n",
      "\n",
      "Iteration 85\n",
      "Cost function: 4.448568427804898 (-0.20%)\n",
      "Gradient norm: 153.30097282812778 (-27.87%)\n",
      "Global relative error: 3.1501990699665723 (-6.20%)\n",
      "Position relative errors: 0.03900224750433183 m, 1.6626346721879213 m, 2.164566222852015 m, 1.5724275747905496 m\n",
      "\n",
      "Iteration 85\n",
      "L_norm = 4.381432801880514\n",
      "Grad_L_norm = 0.009537706360946667\n",
      "\n",
      "Iteration 41\n",
      "Cost function: 3169850.7008281206 (0.00%)\n",
      "Gradient norm: 0.02990449494769143 (194.51%)\n",
      "Global relative error: 386.6603175625063 (-0.00%)\n",
      "Position relative errors: 2.173331707101987 m, 183.52476696928915 m, 237.33265900689503 m, 243.9120187257359 m\n",
      "\n",
      "Iteration 86\n",
      "Cost function: 4.440570119229826 (-0.18%)\n",
      "Gradient norm: 184.3913421421005 (20.28%)\n",
      "Global relative error: 2.9487869612214923 (-6.39%)\n",
      "Position relative errors: 0.038961676344463715 m, 1.553165715499977 m, 2.0309752762524838 m, 1.4685500001136877 m\n",
      "\n",
      "Iteration 86\n",
      "L_norm = 4.381432802546408\n",
      "Grad_L_norm = 0.016674977408317\n",
      "\n",
      "Iteration 87\n",
      "Cost function: 4.433525516899854 (-0.16%)\n",
      "Gradient norm: 136.59921156390533 (-25.92%)\n",
      "Global relative error: 2.76679508386855 (-6.17%)\n",
      "Position relative errors: 0.038895327462365015 m, 1.4544110599438638 m, 1.9283725201096595 m, 1.3489653049663552 m\n",
      "\n",
      "Iteration 87\n",
      "L_norm = 4.381432801412049\n",
      "Grad_L_norm = 0.011101847021826445\n",
      "\n",
      "Iteration 42\n",
      "Cost function: 3169850.700825915 (-0.00%)\n",
      "Gradient norm: 0.022144743845193486 (-25.95%)\n",
      "Global relative error: 386.6603175747019 (0.00%)\n",
      "Position relative errors: 2.1733316942519663 m, 183.524766976653 m, 237.33265900770743 m, 243.91201873885203 m\n",
      "\n",
      "Iteration 88\n",
      "Cost function: 4.427320858766849 (-0.14%)\n",
      "Gradient norm: 160.35585662769063 (17.39%)\n",
      "Global relative error: 2.590907728952767 (-6.36%)\n",
      "Position relative errors: 0.03885823658739634 m, 1.3588754677786763 m, 1.8126051670973575 m, 1.2566664266943117 m\n",
      "\n",
      "Iteration 88\n",
      "L_norm = 4.38143280488408\n",
      "Grad_L_norm = 0.03413803045734704\n",
      "\n",
      "Iteration 89\n",
      "Cost function: 4.421855717065011 (-0.12%)\n",
      "Gradient norm: 121.76581533122197 (-24.07%)\n",
      "Global relative error: 2.4319593904466337 (-6.13%)\n",
      "Position relative errors: 0.038801233294704265 m, 1.2722959675446674 m, 1.7216754826680343 m, 1.153262939140491 m\n",
      "\n",
      "Iteration 89\n",
      "L_norm = 4.381432800122702\n",
      "Grad_L_norm = 0.018904007095926875\n",
      "\n",
      "Iteration 90\n",
      "Cost function: 4.417041928913202 (-0.11%)\n",
      "Gradient norm: 139.7430479036724 (14.76%)\n",
      "Global relative error: 2.2785984827631105 (-6.31%)\n",
      "Position relative errors: 0.03876751508334534 m, 1.1889891720287378 m, 1.6213202964191646 m, 1.071509021575273 m\n",
      "\n",
      "Iteration 43\n",
      "Cost function: 3169850.7008273616 (0.00%)\n",
      "Gradient norm: 0.03843972918638092 (73.58%)\n",
      "Global relative error: 386.66031756676864 (-0.00%)\n",
      "Position relative errors: 2.1733316892309826 m, 183.52476697118942 m, 237.33265900779543 m, 243.912018730346 m\n",
      "\n",
      "Iteration 90\n",
      "L_norm = 4.381432803924151\n",
      "Grad_L_norm = 0.020088118309104546\n",
      "\n",
      "Iteration 91\n",
      "Cost function: 4.412801693265426 (-0.10%)\n",
      "Gradient norm: 108.53670867629916 (-22.33%)\n",
      "Global relative error: 2.1400511817049876 (-6.08%)\n",
      "Position relative errors: 0.0387184409095411 m, 1.113199394454583 m, 1.540913220884218 m, 0.9821873307531684 m\n",
      "\n",
      "Iteration 91\n",
      "L_norm = 4.381432801547463\n",
      "Grad_L_norm = 0.004276966184054185\n",
      "\n",
      "Iteration 92\n",
      "Cost function: 4.409066653939642 (-0.08%)\n",
      "Gradient norm: 121.99412186549061 (12.40%)\n",
      "Global relative error: 2.006612338025061 (-6.24%)\n",
      "Position relative errors: 0.03868791649792649 m, 1.040649484795176 m, 1.4539133939613036 m, 0.9100436579352107 m\n",
      "\n",
      "Iteration 44\n",
      "Cost function: 3169850.7008257406 (-0.00%)\n",
      "Gradient norm: 0.020917773394381067 (-45.58%)\n",
      "Global relative error: 386.6603175705166 (0.00%)\n",
      "Position relative errors: 2.1733316961088485 m, 183.52476697769112 m, 237.3326590058106 m, 243.91201873326537 m\n",
      "\n",
      "Iteration 92\n",
      "L_norm = 4.3814328021642135\n",
      "Grad_L_norm = 0.01583437655705412\n",
      "\n",
      "Iteration 93\n",
      "Cost function: 4.4057765217637925 (-0.07%)\n",
      "Gradient norm: 96.712029392797 (-20.72%)\n",
      "Global relative error: 1.8861618264679623 (-6.00%)\n",
      "Position relative errors: 0.03864558746212538 m, 0.974436720890468 m, 1.3829700017901085 m, 0.8330539204777253 m\n",
      "\n",
      "Iteration 93\n",
      "L_norm = 4.3814328021059294\n",
      "Grad_L_norm = 0.01985604835861745\n",
      "\n",
      "Iteration 94\n",
      "Cost function: 4.402878284847993 (-0.07%)\n",
      "Gradient norm: 106.65996026239492 (10.29%)\n",
      "Global relative error: 1.7703829012427776 (-6.14%)\n",
      "Position relative errors: 0.038618055829940254 m, 0.9113733142730868 m, 1.3075659929760228 m, 0.7696967530558424 m\n",
      "\n",
      "Iteration 45\n",
      "Cost function: 3169850.700825968 (0.00%)\n",
      "Gradient norm: 0.007106799351099772 (-66.03%)\n",
      "Global relative error: 386.6603175662528 (-0.00%)\n",
      "Position relative errors: 2.1733316943038576 m, 183.52476696185963 m, 237.33265900647353 m, 243.91201873778917 m\n",
      "\n",
      "Iteration 94\n",
      "L_norm = 4.381432804444406\n",
      "Grad_L_norm = 0.06999479782338339\n",
      "\n",
      "Iteration 95\n",
      "Cost function: 4.400325209331983 (-0.06%)\n",
      "Gradient norm: 86.13216054184284 (-19.25%)\n",
      "Global relative error: 1.6660200162544239 (-5.89%)\n",
      "Position relative errors: 0.038581473193750875 m, 0.8536783519283282 m, 1.2451167454705085 m, 0.7035984900103769 m\n",
      "\n",
      "Iteration 95\n",
      "L_norm = 4.381432801641782\n",
      "Grad_L_norm = 0.0566755587314039\n",
      "\n",
      "Iteration 96\n",
      "Cost function: 4.398076174603897 (-0.05%)\n",
      "Gradient norm: 93.37008523953892 (8.40%)\n",
      "Global relative error: 1.5659345948679722 (-6.01%)\n",
      "Position relative errors: 0.03855672047022522 m, 0.7990059112267235 m, 1.1797983957169789 m, 0.6483278883423217 m\n",
      "\n",
      "Iteration 46\n",
      "Cost function: 3169850.7008260153 (0.00%)\n",
      "Gradient norm: 0.03784956730857267 (432.58%)\n",
      "Global relative error: 386.66031756663267 (0.00%)\n",
      "Position relative errors: 2.17333169820067 m, 183.52476697391185 m, 237.33265900541977 m, 243.9120187303137 m\n",
      "\n",
      "Iteration 96\n",
      "L_norm = 4.3814328032095675\n",
      "Grad_L_norm = 0.011748362257017152\n",
      "\n",
      "Iteration 97\n",
      "Cost function: 4.396094942145231 (-0.05%)\n",
      "Gradient norm: 76.66268736021308 (-17.89%)\n",
      "Global relative error: 1.475905614839682 (-5.75%)\n",
      "Position relative errors: 0.03852504922489754 m, 0.7489057316315341 m, 1.1249589898994325 m, 0.5919628352727335 m\n",
      "\n",
      "Iteration 97\n",
      "L_norm = 4.381432800705326\n",
      "Grad_L_norm = 0.004088079479124406\n",
      "\n",
      "Iteration 98\n",
      "Cost function: 4.394349615864113 (-0.04%)\n",
      "Gradient norm: 81.8235702856361 (6.73%)\n",
      "Global relative error: 1.389800283936284 (-5.83%)\n",
      "Position relative errors: 0.038502847963245684 m, 0.7016800297064522 m, 1.0684256558230694 m, 0.544218257238087 m\n",
      "\n",
      "Iteration 47\n",
      "Cost function: 3169850.7008285252 (0.00%)\n",
      "Gradient norm: 0.006675801793477375 (-82.36%)\n",
      "Global relative error: 386.66031756829403 (0.00%)\n",
      "Position relative errors: 2.1733316947405465 m, 183.5247669751415 m, 237.33265900528738 m, 243.91201873218182 m\n",
      "\n",
      "Iteration 98\n",
      "L_norm = 4.38143280221254\n",
      "Grad_L_norm = 0.0024616526259431267\n",
      "\n",
      "STOP on Iteration 99\n",
      "Cost function = 4.392812083931747 (-0.03%)\n",
      "Gradient norm = 68.18852255767361 (-16.66%)\n",
      "Global relative error = 1.31256919691085 (-5.56%)\n",
      "Final position relative errors: 0.038475398657710595 m, 0.6583713665654211 m, 1.0203915095100171 m, 0.49669439608740834 m\n",
      "\n",
      "STOP on Iteration 99\n",
      "L_norm = 4.381432803182309\n",
      "Grad_L_norm = 0.015782184692434326\n",
      "\n",
      "Final position relative errors: [0.0381100412032285, 0.27811873735812703, 0.3769570915911182, 0.4036491004435748] m\n",
      "Iteration 48\n",
      "Cost function: 3169850.7008281844 (-0.00%)\n",
      "Gradient norm: 0.01206259438458398 (80.69%)\n",
      "Global relative error: 386.66031757867995 (0.00%)\n",
      "Position relative errors: 2.173331706363806 m, 183.52476697842212 m, 237.3326590078453 m, 243.91201874358504 m\n",
      "\n",
      "Iteration 49\n",
      "Cost function: 3169850.7008248926 (-0.00%)\n",
      "Gradient norm: 0.0400723792047685 (232.20%)\n",
      "Global relative error: 386.6603175743498 (-0.00%)\n",
      "Position relative errors: 2.1733317080584946 m, 183.52476698013538 m, 237.332659006087 m, 243.91201873712745 m\n",
      "\n",
      "Iteration 50\n",
      "Cost function: 3169850.700825816 (0.00%)\n",
      "Gradient norm: 0.026294805322483912 (-34.38%)\n",
      "Global relative error: 386.66031756113955 (-0.00%)\n",
      "Position relative errors: 2.1733316982607316 m, 183.52476696746194 m, 237.33265900511066 m, 243.91201872675904 m\n",
      "\n",
      "Iteration 51\n",
      "Cost function: 3169850.7008267883 (0.00%)\n",
      "Gradient norm: 0.05562332640958456 (111.54%)\n",
      "Global relative error: 386.6603175661269 (0.00%)\n",
      "Position relative errors: 2.1733316953732 m, 183.5247669734574 m, 237.33265900724777 m, 243.91201872810038 m\n",
      "\n",
      "Iteration 52\n",
      "Cost function: 3169850.700826234 (-0.00%)\n",
      "Gradient norm: 0.025127466487199754 (-54.83%)\n",
      "Global relative error: 386.6603175681025 (0.00%)\n",
      "Position relative errors: 2.1733316969154512 m, 183.52476697581514 m, 237.33265900833595 m, 243.91201872838565 m\n",
      "\n",
      "Iteration 53\n",
      "Cost function: 3169850.7008269485 (0.00%)\n",
      "Gradient norm: 0.020626936748482653 (-17.91%)\n",
      "Global relative error: 386.6603175664234 (-0.00%)\n",
      "Position relative errors: 2.1733316941268406 m, 183.52476696514893 m, 237.3326590076934 m, 243.91201873439928 m\n",
      "\n",
      "Iteration 54\n",
      "Cost function: 3169850.7008269215 (-0.00%)\n",
      "Gradient norm: 0.02698768534644352 (30.84%)\n",
      "Global relative error: 386.6603175722527 (0.00%)\n",
      "Position relative errors: 2.173331707201472 m, 183.52476697661157 m, 237.33265900679143 m, 243.91201873577666 m\n",
      "\n",
      "Iteration 55\n",
      "Cost function: 3169850.70082831 (0.00%)\n",
      "Gradient norm: 0.025164318481070674 (-6.76%)\n",
      "Global relative error: 386.66031757134573 (-0.00%)\n",
      "Position relative errors: 2.1733317007971458 m, 183.52476697771658 m, 237.3326590063663 m, 243.91201873397816 m\n",
      "\n",
      "Iteration 56\n",
      "Cost function: 3169850.7008261424 (-0.00%)\n",
      "Gradient norm: 0.01729533278149665 (-31.27%)\n",
      "Global relative error: 386.6603175770558 (0.00%)\n",
      "Position relative errors: 2.17333169783826 m, 183.5247669747397 m, 237.3326590068531 m, 243.91201874482255 m\n",
      "\n",
      "Iteration 57\n",
      "Cost function: 3169850.70082642 (0.00%)\n",
      "Gradient norm: 0.025911447236982934 (49.82%)\n",
      "Global relative error: 386.66031756827203 (-0.00%)\n",
      "Position relative errors: 2.173331699283633 m, 183.52476698195855 m, 237.33265900649928 m, 243.912018725798 m\n",
      "\n",
      "Iteration 58\n",
      "Cost function: 3169850.700827616 (0.00%)\n",
      "Gradient norm: 0.03085723056719206 (19.09%)\n",
      "Global relative error: 386.6603175719005 (0.00%)\n",
      "Position relative errors: 2.1733316963372844 m, 183.5247669744309 m, 237.332659006021 m, 243.9120187377056 m\n",
      "\n",
      "Iteration 59\n",
      "Cost function: 3169850.7008272586 (-0.00%)\n",
      "Gradient norm: 0.030866475718823654 (0.03%)\n",
      "Global relative error: 386.6603175730978 (0.00%)\n",
      "Position relative errors: 2.173331703262633 m, 183.52476697458025 m, 237.33265900746906 m, 243.91201873802046 m\n",
      "\n",
      "Iteration 60\n",
      "Cost function: 3169850.7008267166 (-0.00%)\n",
      "Gradient norm: 0.007836931178122866 (-74.61%)\n",
      "Global relative error: 386.66031756979584 (-0.00%)\n",
      "Position relative errors: 2.173331706895731 m, 183.5247669755252 m, 237.33265900608956 m, 243.9120187333849 m\n",
      "\n",
      "Iteration 61\n",
      "Cost function: 3169850.7008273792 (0.00%)\n",
      "Gradient norm: 0.04042171354538594 (415.78%)\n",
      "Global relative error: 386.6603175708541 (0.00%)\n",
      "Position relative errors: 2.173331710429941 m, 183.52476697866157 m, 237.33265900736728 m, 243.91201873142785 m\n",
      "\n",
      "Iteration 62\n",
      "Cost function: 3169850.7008268167 (-0.00%)\n",
      "Gradient norm: 0.018083064028677757 (-55.26%)\n",
      "Global relative error: 386.660317570109 (-0.00%)\n",
      "Position relative errors: 2.1733316960046998 m, 183.52476697263495 m, 237.33265900822963 m, 243.91201873407073 m\n",
      "\n",
      "Iteration 63\n",
      "Cost function: 3169850.700826618 (-0.00%)\n",
      "Gradient norm: 0.05592035017967229 (209.24%)\n",
      "Global relative error: 386.66031756778466 (-0.00%)\n",
      "Position relative errors: 2.1733317010268043 m, 183.52476696542504 m, 237.33265900579212 m, 243.912018738138 m\n",
      "\n",
      "Iteration 64\n",
      "Cost function: 3169850.700826031 (-0.00%)\n",
      "Gradient norm: 0.0640599175590137 (14.56%)\n",
      "Global relative error: 386.66031756766336 (-0.00%)\n",
      "Position relative errors: 2.1733317086723507 m, 183.52476696830138 m, 237.33265900720608 m, 243.9120187343376 m\n",
      "\n",
      "Iteration 65\n",
      "Cost function: 3169850.700826323 (0.00%)\n",
      "Gradient norm: 0.020547902113684506 (-67.92%)\n",
      "Global relative error: 386.66031756841403 (0.00%)\n",
      "Position relative errors: 2.1733317004429256 m, 183.52476697270833 m, 237.33265900518268 m, 243.91201873425388 m\n",
      "\n",
      "Iteration 66\n",
      "Cost function: 3169850.7008268656 (0.00%)\n",
      "Gradient norm: 0.027506482656101627 (33.87%)\n",
      "Global relative error: 386.66031757030163 (0.00%)\n",
      "Position relative errors: 2.173331693360666 m, 183.52476697011602 m, 237.3326590077747 m, 243.91201873673762 m\n",
      "\n",
      "Iteration 67\n",
      "Cost function: 3169850.700827056 (0.00%)\n",
      "Gradient norm: 0.023310890332806904 (-15.25%)\n",
      "Global relative error: 386.66031757070226 (0.00%)\n",
      "Position relative errors: 2.1733316971126806 m, 183.52476697131561 m, 237.33265900545067 m, 243.912018738698 m\n",
      "\n",
      "Iteration 68\n",
      "Cost function: 3169850.700827237 (0.00%)\n",
      "Gradient norm: 0.08357383291161466 (258.52%)\n",
      "Global relative error: 386.6603175707135 (0.00%)\n",
      "Position relative errors: 2.173331699536531 m, 183.52476697367558 m, 237.33265900620947 m, 243.91201873618033 m\n",
      "\n",
      "Iteration 69\n",
      "Cost function: 3169850.7008273457 (0.00%)\n",
      "Gradient norm: 0.04203431084152872 (-49.70%)\n",
      "Global relative error: 386.6603175727906 (0.00%)\n",
      "Position relative errors: 2.173331706068882 m, 183.52476697472457 m, 237.33265900779915 m, 243.9120187370786 m\n",
      "\n",
      "Iteration 70\n",
      "Cost function: 3169850.7008278607 (0.00%)\n",
      "Gradient norm: 0.0117056444592322 (-72.15%)\n",
      "Global relative error: 386.66031757093526 (-0.00%)\n",
      "Position relative errors: 2.1733317063329833 m, 183.52476697251544 m, 237.33265900739988 m, 243.91201873618593 m\n",
      "\n",
      "Iteration 71\n",
      "Cost function: 3169850.7008271907 (-0.00%)\n",
      "Gradient norm: 0.026842821057116054 (129.32%)\n",
      "Global relative error: 386.66031757469534 (0.00%)\n",
      "Position relative errors: 2.1733317080549805 m, 183.52476698173322 m, 237.33265900630644 m, 243.91201873625945 m\n",
      "\n",
      "Iteration 72\n",
      "Cost function: 3169850.700826539 (-0.00%)\n",
      "Gradient norm: 0.05019779243500572 (87.01%)\n",
      "Global relative error: 386.66031756961604 (-0.00%)\n",
      "Position relative errors: 2.1733317034990183 m, 183.52476696830803 m, 237.33265900737035 m, 243.91201873731427 m\n",
      "\n",
      "Iteration 73\n",
      "Cost function: 3169850.7008265518 (0.00%)\n",
      "Gradient norm: 0.03555191182680618 (-29.18%)\n",
      "Global relative error: 386.6603175674808 (-0.00%)\n",
      "Position relative errors: 2.1733317029416606 m, 183.52476697136947 m, 237.33265900645804 m, 243.9120187325186 m\n",
      "\n",
      "Iteration 74\n",
      "Cost function: 3169850.7008267734 (0.00%)\n",
      "Gradient norm: 0.024920525983764538 (-29.90%)\n",
      "Global relative error: 386.66031756812976 (0.00%)\n",
      "Position relative errors: 2.173331702405816 m, 183.52476697265493 m, 237.33265900682102 m, 243.91201873223176 m\n",
      "\n",
      "Iteration 75\n",
      "Cost function: 3169850.7008271934 (0.00%)\n",
      "Gradient norm: 0.034380824690716405 (37.96%)\n",
      "Global relative error: 386.66031757029793 (0.00%)\n",
      "Position relative errors: 2.1733317062644595 m, 183.52476697135077 m, 237.33265900745195 m, 243.91201873600176 m\n",
      "\n",
      "Iteration 76\n",
      "Cost function: 3169850.7008281327 (0.00%)\n",
      "Gradient norm: 0.034438080944270935 (0.17%)\n",
      "Global relative error: 386.66031757480636 (0.00%)\n",
      "Position relative errors: 2.1733317032762782 m, 183.524766977083 m, 237.33265900531822 m, 243.91201874093852 m\n",
      "\n",
      "Iteration 77\n",
      "Cost function: 3169850.7008253057 (-0.00%)\n",
      "Gradient norm: 0.0387291442540624 (12.46%)\n",
      "Global relative error: 386.66031757648415 (0.00%)\n",
      "Position relative errors: 2.1733317041411566 m, 183.52476698193237 m, 237.33265900835744 m, 243.91201873698452 m\n",
      "\n",
      "Iteration 78\n",
      "Cost function: 3169850.700826867 (0.00%)\n",
      "Gradient norm: 0.03675718563727999 (-5.09%)\n",
      "Global relative error: 386.6603175657741 (-0.00%)\n",
      "Position relative errors: 2.1733317024079692 m, 183.5247669740001 m, 237.33265900569097 m, 243.9120187285849 m\n",
      "\n",
      "Iteration 79\n",
      "Cost function: 3169850.700826816 (-0.00%)\n",
      "Gradient norm: 0.014277997355235538 (-61.16%)\n",
      "Global relative error: 386.66031757183566 (0.00%)\n",
      "Position relative errors: 2.1733316966911085 m, 183.52476696994484 m, 237.33265900695346 m, 243.91201874006768 m\n",
      "\n",
      "Iteration 80\n",
      "Cost function: 3169850.700827002 (0.00%)\n",
      "Gradient norm: 0.04548081502977091 (218.54%)\n",
      "Global relative error: 386.6603175690175 (-0.00%)\n",
      "Position relative errors: 2.173331702234188 m, 183.5247669703061 m, 237.33265900698902 m, 243.91201873524437 m\n",
      "\n",
      "Iteration 81\n",
      "Cost function: 3169850.7008264917 (-0.00%)\n",
      "Gradient norm: 0.005294132548561759 (-88.36%)\n",
      "Global relative error: 386.6603175718567 (0.00%)\n",
      "Position relative errors: 2.173331699433232 m, 183.52476697573834 m, 237.3326590077618 m, 243.9120187349309 m\n",
      "\n",
      "Iteration 82\n",
      "Cost function: 3169850.700826783 (0.00%)\n",
      "Gradient norm: 0.011128926516857318 (110.21%)\n",
      "Global relative error: 386.66031756856205 (-0.00%)\n",
      "Position relative errors: 2.1733316985799163 m, 183.52476697158758 m, 237.33265900659296 m, 243.91201873397614 m\n",
      "\n",
      "Iteration 83\n",
      "Cost function: 3169850.7008272903 (0.00%)\n",
      "Gradient norm: 0.01917622276547054 (72.31%)\n",
      "Global relative error: 386.66031757283764 (0.00%)\n",
      "Position relative errors: 2.173331695167461 m, 183.52476698058075 m, 237.3326590063924 m, 243.91201873421286 m\n",
      "\n",
      "Iteration 84\n",
      "Cost function: 3169850.70082606 (-0.00%)\n",
      "Gradient norm: 0.029791210587237063 (55.35%)\n",
      "Global relative error: 386.6603175703232 (-0.00%)\n",
      "Position relative errors: 2.1733317001043067 m, 183.52476697579402 m, 237.33265900584414 m, 243.91201873431794 m\n",
      "\n",
      "Iteration 85\n",
      "Cost function: 3169850.7008263655 (0.00%)\n",
      "Gradient norm: 0.040977599891774186 (37.55%)\n",
      "Global relative error: 386.66031756924485 (-0.00%)\n",
      "Position relative errors: 2.173331707078317 m, 183.52476697582833 m, 237.3326590069325 m, 243.91201873146164 m\n",
      "\n",
      "Iteration 86\n",
      "Cost function: 3169850.7008269634 (0.00%)\n",
      "Gradient norm: 0.016595055577523606 (-59.50%)\n",
      "Global relative error: 386.6603175707784 (0.00%)\n",
      "Position relative errors: 2.1733316982143456 m, 183.52476697746457 m, 237.3326590072969 m, 243.91201873238595 m\n",
      "\n",
      "Iteration 87\n",
      "Cost function: 3169850.7008284465 (0.00%)\n",
      "Gradient norm: 0.018391787881094992 (10.83%)\n",
      "Global relative error: 386.66031757362146 (0.00%)\n",
      "Position relative errors: 2.173331694200977 m, 183.52476697567974 m, 237.33265900678794 m, 243.9120187387668 m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# DISTRIBUTED OVER SEVERAL CPUs\n",
    "def solve_algorithm(algorithm_name, algorithm, X_est, dt, Y, X_true, n):\n",
    "    \"\"\"\n",
    "    Solves the estimation problem for a given algorithm.\n",
    "    Returns the algorithm name, updated X_est, and cost function/gradient data for plotting.\n",
    "    \"\"\"\n",
    "    print(f\"-------- {algorithm_name} --------\")\n",
    "    \n",
    "    if algorithm_name == \"Centralized Newton\":\n",
    "        X_est = algorithm.solve_for_each_window(dt, X_est, Y[:, :, n : n + W])\n",
    "        final_errors = [\n",
    "            np.linalg.norm(X_true[:3, :, n] - X_est[:3]),\n",
    "            np.linalg.norm(X_true[6:9, :, n] - X_est[6:9]),\n",
    "            np.linalg.norm(X_true[12:15, :, n] - X_est[12:15]),\n",
    "            np.linalg.norm(X_true[18:21, :, n] - X_est[18:21])\n",
    "        ]\n",
    "        print(f\"Final position relative errors: {final_errors} m\")\n",
    "    \n",
    "    elif algorithm_name in [\"ApproxH Newton\", \"MM Newton\"]:\n",
    "        X_est = algorithm.solve_for_each_window(dt, X_est, Y[:, :, n : n + W], X_true[:, :, n])\n",
    "\n",
    "    # Collect cost function and gradient norm data\n",
    "    return (\n",
    "        algorithm_name,\n",
    "        X_est,\n",
    "        algorithm.cost_function_values.copy(),\n",
    "        algorithm.grad_norm_values.copy(),\n",
    "        algorithm.surrogate_function_values.copy() if hasattr(algorithm, \"surrogate_function_values\") else [],\n",
    "        algorithm.surrogate_grad_norm_values.copy() if hasattr(algorithm, \"surrogate_grad_norm_values\") else []\n",
    "    )\n",
    "\n",
    "# ================= MAIN EXECUTION =================\n",
    "for m in tqdm(range(M), desc=\"MC runs\", leave=True):\n",
    "    # Generate observations\n",
    "    Y = np.zeros((9, 1, T))\n",
    "    for t in range(T):\n",
    "        Y[:, :, t] = unkkt.h(X_true[:, :, t]) + np.random.multivariate_normal(np.zeros(9), R).reshape((9, 1))\n",
    "\n",
    "    # Initialize state estimates\n",
    "    X_est_unkkt = X_initial + initial_dev\n",
    "    X_est_approx_newton = X_initial + initial_dev\n",
    "    X_est_mm = X_initial + initial_dev\n",
    "\n",
    "    for n in tqdm(range(K - W + 1), desc=\"Windows\", leave=False):\n",
    "        with ProcessPoolExecutor(max_workers=3) as executor:\n",
    "            # Run each algorithm in parallel\n",
    "            future_to_algorithm = {\n",
    "                executor.submit(solve_algorithm, \"Centralized Newton\", unkkt, X_est_unkkt, dt, Y, X_true, n): \"Centralized Newton\",\n",
    "                executor.submit(solve_algorithm, \"ApproxH Newton\", approxh_newton, X_est_approx_newton, dt, Y, X_true, n): \"ApproxH Newton\",\n",
    "                executor.submit(solve_algorithm, \"MM Newton\", mm_newton, X_est_mm, dt, Y, X_true, n): \"MM Newton\"\n",
    "            }\n",
    "\n",
    "            # Retrieve results in the main process\n",
    "            results = {future.result()[0]: future.result()[1:] for future in future_to_algorithm}\n",
    "\n",
    "        # Extract updated estimates\n",
    "        X_est_unkkt, cost_unkkt, grad_unkkt, _, _ = results[\"Centralized Newton\"]\n",
    "        X_est_approx_newton, cost_approx, grad_approx, _, _ = results[\"ApproxH Newton\"]\n",
    "        X_est_mm, cost_mm, grad_mm, surrogate_cost_mm, surrogate_grad_mm = results[\"MM Newton\"]\n",
    "\n",
    "        # Plot results **in the main process**\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(2 * 6.4, 4.8))\n",
    "\n",
    "        # Cost function values\n",
    "        ax1.plot(cost_unkkt, '.-', label='Centralized Newton')\n",
    "        ax1.plot(cost_approx, '.-', label='ApproxH Newton')\n",
    "        ax1.plot(cost_mm, '.-', label='MM Newton Cost Function')\n",
    "        ax1.plot(surrogate_cost_mm, '.-', label='MM Newton Surrogate Function')\n",
    "        ax1.set_xlabel('Iteration')\n",
    "        ax1.set_ylabel(r'$\\frac{1}{W}$ Cost Function')\n",
    "        ax1.set_yscale('log')\n",
    "        ax1.grid(True)\n",
    "        ax1.legend()\n",
    "\n",
    "        # Gradient norm values\n",
    "        ax2.plot(grad_unkkt, '.-', label='Centralized Newton')\n",
    "        ax2.plot(grad_approx, '.-', label='ApproxH Newton')\n",
    "        ax2.plot(grad_mm, '.-', label='MM Newton Cost Function Gradient Norm')\n",
    "        ax2.plot(surrogate_grad_mm, '.-', label='MM Newton Surrogate Function Gradient Norm')\n",
    "        ax2.set_xlabel('Iteration')\n",
    "        ax2.set_ylabel(r'$\\frac{1}{W}$ Gradient Norm')\n",
    "        ax2.set_yscale('log')\n",
    "        ax2.grid(True)\n",
    "        ax2.legend()\n",
    "\n",
    "        fig.suptitle(f'Window {n + 1}')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        # Update state estimates\n",
    "        X_est_unkkt = unkkt.dynamic_model.x_new(dt, X_est_unkkt)\n",
    "        X_est_approx_newton = approxh_newton.dynamic_model.x_new(dt, X_est_approx_newton)\n",
    "        X_est_mm = mm_newton.dynamic_model.x_new(dt, X_est_mm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SEQUENTIAL USING ONE CPU\n",
    "# Main execution loop\n",
    "for m in tqdm(range(M), desc=\"MC runs\", leave=True):\n",
    "    # Observations\n",
    "    Y = np.zeros((9, 1, T))\n",
    "    for t in range(T):\n",
    "        Y[:, :, t] = unkkt.h(X_true[:, :, t]) + np.random.multivariate_normal(np.zeros(9), R).reshape((9, 1))\n",
    "\n",
    "    # Estimate the state\n",
    "    X_est_unkkt = X_initial + initial_dev\n",
    "    X_est_approx_newton = X_initial + initial_dev\n",
    "    X_est_mm = X_initial + initial_dev\n",
    "    for n in tqdm(range(K - W + 1), desc=\"Windows\", leave=False):\n",
    "        print(\"-------- Centralized Newton --------\")\n",
    "        X_est_unkkt = unkkt.solve_for_each_window(dt, X_est_unkkt, Y[:, :, n : n + W])\n",
    "        print(f\"Final position relative errors: {np.linalg.norm(X_true[:3, :, n] - X_est_unkkt[:3])} m, {np.linalg.norm(X_true[6:9, :, n] - X_est_unkkt[6:9])} m, {np.linalg.norm(X_true[12:15, :, n] - X_est_unkkt[12:15])} m, {np.linalg.norm(X_true[18:21, :, n] - X_est_unkkt[18:21])} m\")\n",
    "        print(\"-------- ApproxH Newton --------\")\n",
    "        X_est_approx_newton = approxh_newton.solve_for_each_window(dt, X_est_approx_newton, Y[:, :, n : n + W], X_true[:, :, n])\n",
    "        print(\"-------- MM Newton --------\")\n",
    "        X_est_mm = mm_newton.solve_for_each_window(dt, X_est_mm, Y[:, :, n : n + W], X_true[:, :, n])\n",
    "\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(2 * 6.4, 4.8))\n",
    "\n",
    "        # First subplot - Cost function values\n",
    "        ax1.plot(unkkt.cost_function_values, '.-', label='Centralized Newton')\n",
    "        ax1.plot(approxh_newton.cost_function_values, '.-', label='ApproxH Newton')\n",
    "        ax1.plot(mm_newton.cost_function_values, '.-', label='MM Newton Cost Function')\n",
    "        ax1.plot(mm_newton.surrogate_function_values, '.-', label='MM Newton Surrogate Function')\n",
    "        ax1.set_xlabel('Iteration')\n",
    "        ax1.set_ylabel('$\\frac{1}{W}$ Cost Function')\n",
    "        ax1.set_yscale('log')\n",
    "        ax1.grid(True)\n",
    "        ax1.legend()\n",
    "\n",
    "        # Second subplot - Gradient norm values\n",
    "        ax2.plot(unkkt.grad_norm_values, '.-', label='Centralized Newton')\n",
    "        ax2.plot(approxh_newton.grad_norm_values, '.-', label='ApproxH Newton')\n",
    "        ax2.plot(mm_newton.grad_norm_values, '.-', label='MM Newton Cost Function Gradient Norm')\n",
    "        ax2.plot(mm_newton.surrogate_grad_norm_values, '.-', label='MM Newton Surrogate Function Gradient Norm')\n",
    "        ax2.set_xlabel('Iteration')\n",
    "        ax2.set_ylabel('$\\frac{1}{W}$Gradient Norm')\n",
    "        ax2.set_yscale('log')\n",
    "        ax2.grid(True)\n",
    "        ax2.legend()\n",
    "\n",
    "        plt.title(f'Window {n + 1}')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        unkkt.cost_function_values = []\n",
    "        unkkt.grad_norm_values = []\n",
    "        approxh_newton.cost_function_values = []\n",
    "        approxh_newton.grad_norm_values = []\n",
    "        mm_newton.cost_function_values = []\n",
    "        mm_newton.grad_norm_values = []\n",
    "        mm_newton.surrogate_function_values = []\n",
    "        mm_newton.surrogate_grad_norm_values = []\n",
    "        \n",
    "        X_est_unkkt = unkkt.dynamic_model.x_new(dt, X_est_unkkt)\n",
    "        X_est_approx_newton = approxh_newton.dynamic_model.x_new(dt, X_est_approx_newton)\n",
    "        X_est_mm = mm_newton.dynamic_model.x_new(dt, X_est_mm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
