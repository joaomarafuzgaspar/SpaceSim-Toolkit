{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "from dataclasses import dataclass\n",
    "from scipy.linalg import solve, block_diag\n",
    "\n",
    "from dynamics import Dynamics, coe2rv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class SimulationConfig:\n",
    "    # Simulation parameters\n",
    "    dt: float = 10.0  # Time step [s] (1, 5, 10, 20, 30, 60)\n",
    "    K: int = (\n",
    "        6\n",
    "        * 395  # Simulation duration in timesteps (57000, 11400, 5700, 2850, 1900, 950)\n",
    "    )\n",
    "    H: int = 2  # Window size [timesteps]\n",
    "    seed: int = 42  # Random seed for reproducibility\n",
    "\n",
    "    # Network parameters\n",
    "    N: int = 10  # Number of systems\n",
    "    number_of_chiefs: int = 1  # Number of chiefs\n",
    "    number_of_deputies: int = N - number_of_chiefs  # Number of deputies\n",
    "    n_p: int = 3  # Position vector dimension\n",
    "    n_v: int = 3  # Velocity vector dimension\n",
    "    n_x: int = n_p + n_v  # State vector dimension\n",
    "    n: int = N * n_x  # Global state vector dimension\n",
    "    o_chief: int = 3  # Chief observation vector dimension\n",
    "    o_deputy: int = 3  # Deputy observation vector dimension\n",
    "    o: int = (\n",
    "        number_of_chiefs * o_chief + number_of_deputies * o_deputy\n",
    "    )  # Global observation vector dimension\n",
    "\n",
    "    # Observation noise\n",
    "    r_chief_pos: float = 1e-1  # [m]\n",
    "    R_chief: np.ndarray = np.diag(np.concatenate([r_chief_pos * np.ones(o_chief)])) ** 2\n",
    "    r_deputy_pos: float = 1e0  # [m]\n",
    "    R_deputy: np.ndarray = (\n",
    "        np.diag(np.concatenate([r_deputy_pos * np.ones(o_deputy)])) ** 2\n",
    "    )\n",
    "    R_deputies: np.ndarray = block_diag(R_deputy, R_deputy, R_deputy, R_deputy, R_deputy, R_deputy, R_deputy, R_deputy, R_deputy)\n",
    "    R: np.ndarray = block_diag(R_chief, R_deputies)\n",
    "\n",
    "    # Initial deviation noise\n",
    "    # Warm-start parameters\n",
    "    p_pos_initial: float = 1e3  # [m]\n",
    "    p_vel_initial: float = 1e1  # [m / s]\n",
    "    # Cold-start parameters\n",
    "    # p_pos_initial: float = 1e2  # [m]\n",
    "    # p_vel_initial: float = 1e0  # [m / s]\n",
    "    P_0_spacecraft: np.ndarray = (\n",
    "        np.diag(\n",
    "            np.concatenate([p_pos_initial * np.ones(n_p), p_vel_initial * np.ones(n_v)])\n",
    "        )\n",
    "        ** 2\n",
    "    )\n",
    "    P_0: np.ndarray = block_diag(\n",
    "        P_0_spacecraft, P_0_spacecraft, P_0_spacecraft, P_0_spacecraft,\n",
    "        P_0_spacecraft, P_0_spacecraft, P_0_spacecraft, P_0_spacecraft,\n",
    "        P_0_spacecraft, P_0_spacecraft\n",
    "    )\n",
    "\n",
    "    # Levenberg-Marquardt parameters\n",
    "    lambda_0: float = 1.0\n",
    "    epsilon: float = 1e-6\n",
    "    max_iter: int = 100\n",
    "\n",
    "    # Consensus parameters\n",
    "    L: int = 1  # Number of consensus iterations\n",
    "    gamma: float = N  # Consensus gain 1\n",
    "    pi: float = 1 / N  # Consensus gain 2\n",
    "\n",
    "    # Newton's method-based algorithms parameters\n",
    "    grad_norm_order_mag: bool = True\n",
    "    grad_norm_tol: float = 1e-6\n",
    "    max_iterations: int = 20\n",
    "\n",
    "    # Majorization-Minimization parameters\n",
    "    mm_tol: float = 1e0\n",
    "    mm_max_iter: int = 20\n",
    "\n",
    "    # Post-processing parameters\n",
    "    invalid_rmse: float = 1e2  # [m]\n",
    "    K_RMSE: int = H  # Index from which the RMSE is calculated\n",
    "\n",
    "    # Spacecraft parameters\n",
    "    mass: float = 1.0  # Mass [kg]\n",
    "    C_drag: float = 2.2  # Drag coefficient\n",
    "    A_drag: float = 0.01  # Drag area [m^2]\n",
    "    C_SRP: float = 1.2  # SRP coefficient\n",
    "    A_SRP: float = 0.01  # SRP area [m^2]\n",
    "\n",
    "    # Observation model\n",
    "    @classmethod\n",
    "    def h(cls, x_vec):\n",
    "        p_vecs = [x_vec[i : i + cls.n_p] for i in range(0, cls.n, cls.n_x)]\n",
    "        distances = [p_vecs[i] - p_vecs[j] for (i, j) in [(1, 0), (2, 0), (3, 1), (4, 1), (5, 2), (6, 2), (7, 3), (8, 3), (9, 5)]]\n",
    "        return np.concatenate((p_vecs[0], np.array(distances).reshape(-1, 1)))\n",
    "\n",
    "    @classmethod\n",
    "    def Dh(cls, x_vec):\n",
    "        first_order_der = np.zeros((cls.o, cls.n))\n",
    "\n",
    "        first_order_der[: cls.n_p, : cls.n_p] = np.eye(cls.n_p)\n",
    "\n",
    "        for k, (i, j) in enumerate([(1, 0), (2, 0), (3, 1), (4, 1), (5, 2), (6, 2), (7, 3), (8, 3), (9, 5)], start=1):\n",
    "            first_order_der[\n",
    "                cls.n_p * k : cls.n_p * (k + 1), i * cls.n_x : i * cls.n_x + cls.n_p\n",
    "            ] = np.eye(cls.n_p)\n",
    "            first_order_der[\n",
    "                cls.n_p * k : cls.n_p * (k + 1), j * cls.n_x : j * cls.n_x + cls.n_p\n",
    "            ] = -np.eye(cls.n_p)\n",
    "\n",
    "        return first_order_der\n",
    "\n",
    "    @classmethod\n",
    "    def Hh(cls, x_vec):\n",
    "        return np.zeros((cls.o * cls.n, cls.n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = SimulationConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Newton:\n",
    "    def __init__(self):\n",
    "        # Simulation parameters\n",
    "        self.H = config.H\n",
    "        self.K = config.K\n",
    "        self.dt = config.dt\n",
    "        self.o = config.o\n",
    "        self.R = config.R\n",
    "        self.dyn = Dynamics()\n",
    "\n",
    "        # Stopping criteria\n",
    "        self.grad_norm_order_mag = config.grad_norm_order_mag\n",
    "        self.grad_norm_tol = config.grad_norm_tol\n",
    "        self.max_iterations = config.max_iterations\n",
    "\n",
    "        # Storage for results\n",
    "        self.iterations = None\n",
    "        self.cost_values = []\n",
    "        self.gradient_norm_values = []\n",
    "        self.grad_norm_order_history = []\n",
    "        self.HJ_x_eigenvalues_history = []\n",
    "        self.A_norm_history, self.B_norm_history, self.C_norm_history = [], [], []\n",
    "\n",
    "        # Observation model\n",
    "        self.h = config.h\n",
    "        self.Dh = config.Dh\n",
    "        self.Hh = config.Hh\n",
    "\n",
    "    def J(self, k, Y, x_vec):\n",
    "        if k < self.H - 1 or k + 1 > self.K:\n",
    "            raise ValueError(\"k is out of bounds\")\n",
    "        R_inv = np.linalg.inv(self.R)\n",
    "        J_x = 0\n",
    "        for tau in range(k - self.H + 1, k + 1):\n",
    "            y = Y[:, :, tau]\n",
    "            h_x = self.h(x_vec)\n",
    "            J_x += 1 / 2 * (y - h_x).T @ R_inv @ (y - h_x)\n",
    "            x_vec = self.dyn.f(self.dt, x_vec)\n",
    "        return J_x\n",
    "\n",
    "    def DJ(self, k, Y, x_vec):\n",
    "        if k < self.H - 1 or k + 1 > self.K:\n",
    "            raise ValueError(\"k is out of bounds\")\n",
    "        R_inv = np.linalg.inv(self.R)\n",
    "        STM = np.eye(config.n)\n",
    "        DJ_x = np.zeros((config.n, 1))\n",
    "        for tau in range(k - self.H + 1, k + 1):\n",
    "            y = Y[:, :, tau]\n",
    "            DJ_x += -STM.T @ self.Dh(x_vec).T @ R_inv @ (y - self.h(x_vec))\n",
    "            STM = self.dyn.Df(self.dt, x_vec) @ STM\n",
    "            x_vec = self.dyn.f(self.dt, x_vec)\n",
    "        return DJ_x\n",
    "\n",
    "    def HJ(self, k, Y, x_vec):\n",
    "        if k < self.H - 1 or k + 1 > self.K:\n",
    "            raise ValueError(\"k is out of bounds\")\n",
    "        R_inv = np.linalg.inv(self.R)\n",
    "        STM = np.eye(config.n)\n",
    "        DSTM = np.zeros((config.n * config.n, config.n))\n",
    "        HJ_x = np.zeros((config.n, config.n))\n",
    "        for tau in range(k - self.H + 1, k + 1):\n",
    "            y = Y[:, :, tau]\n",
    "            h_x = self.h(x_vec)\n",
    "            Dh_x = self.Dh(x_vec)\n",
    "            Hh_x = self.Hh(x_vec)\n",
    "            Df_x = STM\n",
    "            Hf_x = DSTM\n",
    "            HJ_x += (\n",
    "                -(\n",
    "                    np.kron(R_inv @ (y - h_x), Df_x).T @ Hh_x @ Df_x\n",
    "                    + np.kron(Dh_x.T @ R_inv @ (y - h_x), np.eye(config.n)).T @ Hf_x\n",
    "                )\n",
    "                + Df_x.T @ Dh_x.T @ R_inv @ Dh_x @ Df_x\n",
    "            )\n",
    "            DSTM = (\n",
    "                np.kron(np.eye(config.n), STM).T @ self.dyn.Hf(self.dt, x_vec) @ STM\n",
    "                + np.kron(self.dyn.Df(self.dt, x_vec), np.eye(config.n)) @ DSTM\n",
    "            )\n",
    "            STM = self.dyn.Df(self.dt, x_vec) @ STM\n",
    "            x_vec = self.dyn.f(self.dt, x_vec)\n",
    "        return HJ_x\n",
    "\n",
    "    def solve_MHE_problem(self, k, Y, x_init, x_true_initial, x_true_end):\n",
    "        x = x_init.copy()\n",
    "\n",
    "        prev_cost_value = None\n",
    "        prev_gradient_norm_value = None\n",
    "        prev_global_estimation_error = None\n",
    "        grad_norm_order_history = []\n",
    "\n",
    "        for iteration in range(self.max_iterations + 1):\n",
    "            # Compute the cost function, gradient of the Lagrangian and Hessian of the Lagrangian\n",
    "            J_x = self.J(k, Y, x)\n",
    "            DJ_x = self.DJ(k, Y, x)\n",
    "            HJ_x = self.HJ(k, Y, x)\n",
    "\n",
    "            # Convergence tracking\n",
    "            cost_value = J_x[0][0]\n",
    "            gradient_norm_value = np.linalg.norm(DJ_x)\n",
    "\n",
    "            # Store the values\n",
    "            self.cost_values.append(cost_value)\n",
    "            self.gradient_norm_values.append(gradient_norm_value)\n",
    "\n",
    "            # Metrics\n",
    "            if prev_cost_value is not None:\n",
    "                cost_value_change = (\n",
    "                    (cost_value - prev_cost_value) / abs(prev_cost_value) * 100\n",
    "                )\n",
    "                gradient_norm_value_change = (\n",
    "                    (gradient_norm_value - prev_gradient_norm_value)\n",
    "                    / abs(prev_gradient_norm_value)\n",
    "                    * 100\n",
    "                )\n",
    "                global_estimation_error_change = (\n",
    "                    (np.linalg.norm(x - x_true_initial) - prev_global_estimation_error)\n",
    "                    / abs(prev_global_estimation_error)\n",
    "                    * 100\n",
    "                )\n",
    "            prev_cost_value = cost_value\n",
    "            prev_gradient_norm_value = gradient_norm_value\n",
    "            prev_global_estimation_error = np.linalg.norm(x - x_true_initial)\n",
    "\n",
    "            # Track gradient norm order of magnitude\n",
    "            current_order = int(\n",
    "                np.floor(np.log10(gradient_norm_value + 1e-12))\n",
    "            )  # avoid log(0)\n",
    "            grad_norm_order_history.append(current_order)\n",
    "\n",
    "            if self.grad_norm_order_mag:\n",
    "                if len(grad_norm_order_history) >= 3:\n",
    "                    if (\n",
    "                        grad_norm_order_history[-1]\n",
    "                        == grad_norm_order_history[-2]\n",
    "                        == grad_norm_order_history[-3]\n",
    "                    ):\n",
    "                        stagnant_order = True\n",
    "                        if k == self.H - 1:\n",
    "                            stagnant_order = False\n",
    "                    else:\n",
    "                        stagnant_order = False\n",
    "                else:\n",
    "                    stagnant_order = False\n",
    "            else:\n",
    "                stagnant_order = False\n",
    "\n",
    "            # Propagate window initial conditions for metrics\n",
    "            x_end = x.copy()\n",
    "            for _ in range(self.H - 1):\n",
    "                x_end = self.dyn.f(self.dt, x_end)\n",
    "\n",
    "            # Check convergence and print metrics\n",
    "            if (\n",
    "                gradient_norm_value < self.grad_norm_tol\n",
    "                or iteration == self.max_iterations\n",
    "                or stagnant_order\n",
    "            ):\n",
    "                reason = (\n",
    "                    \"tolerance reached\"\n",
    "                    if gradient_norm_value < self.grad_norm_tol\n",
    "                    else (\n",
    "                        \"max iteration reached\"\n",
    "                        if iteration == self.max_iterations\n",
    "                        else \"gradient norm stagnated\"\n",
    "                    )\n",
    "                )\n",
    "                print(f\"[Newton] STOP on Iteration {iteration} ({reason})\")\n",
    "                print(\n",
    "                    f\"Cost function = {cost_value} ({cost_value_change:.2f}%)\\nGradient norm = {gradient_norm_value} ({gradient_norm_value_change:.2f}%)\\nGlobal estimation error = {np.linalg.norm(x - x_true_initial)} ({global_estimation_error_change:.2f}%)\"\n",
    "                )\n",
    "                print(\n",
    "                    f\"Final initial conditions estimation errors: {np.linalg.norm(x[:config.n_p, :] - x_true_initial[:config.n_p, :])} m, {np.linalg.norm(x[config.n_x : config.n_x + config.n_p, :] - x_true_initial[config.n_x : config.n_x + config.n_p, :])} m, {np.linalg.norm(x[2 * config.n_x : 2 * config.n_x + config.n_p, :] - x_true_initial[2 * config.n_x : 2 * config.n_x + config.n_p, :])} m, {np.linalg.norm(x[3 * config.n_x : 3 * config.n_x + config.n_p, :] - x_true_initial[3 * config.n_x : 3 * config.n_x + config.n_p, :])} m\"\n",
    "                )\n",
    "                print(\n",
    "                    f\"Final position estimation errors: {np.linalg.norm(x_end[:config.n_p, :] - x_true_end[:config.n_p, :])} m, {np.linalg.norm(x_end[config.n_x : config.n_x + config.n_p, :] - x_true_end[config.n_x : config.n_x + config.n_p, :])} m, {np.linalg.norm(x_end[2 * config.n_x : 2 * config.n_x + config.n_p, :] - x_true_end[2 * config.n_x : 2 * config.n_x + config.n_p, :])} m, {np.linalg.norm(x_end[3 * config.n_x : 3 * config.n_x + config.n_p, :] - x_true_end[3 * config.n_x : 3 * config.n_x + config.n_p, :])} m\\n\"\n",
    "                )\n",
    "                break\n",
    "            else:\n",
    "                if iteration == 0:\n",
    "                    print(\n",
    "                        f\"[Newton] Before applying the algorithm\\nCost function: {cost_value}\\nGradient norm: {gradient_norm_value}\\nGlobal estimation error: {np.linalg.norm(x - x_true_initial)}\"\n",
    "                    )\n",
    "                else:\n",
    "                    print(\n",
    "                        f\"[Newton] Iteration {iteration}\\nCost function: {cost_value} ({cost_value_change:.2f}%)\\nGradient norm: {gradient_norm_value} ({gradient_norm_value_change:.2f}%)\\nGlobal estimation error: {np.linalg.norm(x - x_true_initial)} ({global_estimation_error_change:.2f}%)\"\n",
    "                    )\n",
    "\n",
    "            # Print estimation errors\n",
    "            print(\n",
    "                f\"Initial conditions estimation errors: {np.linalg.norm(x[:config.n_p, :] - x_true_initial[:config.n_p, :])} m, {np.linalg.norm(x[config.n_x : config.n_x + config.n_p, :] - x_true_initial[config.n_x : config.n_x + config.n_p, :])} m, {np.linalg.norm(x[2 * config.n_x : 2 * config.n_x + config.n_p, :] - x_true_initial[2 * config.n_x : 2 * config.n_x + config.n_p, :])} m, {np.linalg.norm(x[3 * config.n_x : 3 * config.n_x + config.n_p, :] - x_true_initial[3 * config.n_x : 3 * config.n_x + config.n_p, :])} m\"\n",
    "            )\n",
    "            print(\n",
    "                f\"Position estimation errors: {np.linalg.norm(x_end[:config.n_p, :] - x_true_end[:config.n_p, :])} m, {np.linalg.norm(x_end[config.n_x : config.n_x + config.n_p, :] - x_true_end[config.n_x : config.n_x + config.n_p, :])} m, {np.linalg.norm(x_end[2 * config.n_x : 2 * config.n_x + config.n_p, :] - x_true_end[2 * config.n_x : 2 * config.n_x + config.n_p, :])} m, {np.linalg.norm(x_end[3 * config.n_x : 3 * config.n_x + config.n_p, :] - x_true_end[3 * config.n_x : 3 * config.n_x + config.n_p, :])} m\\n\"\n",
    "            )\n",
    "\n",
    "            # Solve for the Newton step - this is one iteration\n",
    "            delta_x = solve(HJ_x, -DJ_x)\n",
    "            x += delta_x\n",
    "\n",
    "            # Save the current iteration\n",
    "            self.iterations = iteration + 1\n",
    "\n",
    "        # Propagate window initial conditions getting estimate at timestamp k\n",
    "        x_init = x\n",
    "        for _ in range(self.H - 1):\n",
    "            x = self.dyn.f(self.dt, x)\n",
    "\n",
    "        return x_init, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_form_initial_conditions():\n",
    "    # Nominal (chief) orbit parameters\n",
    "    semi_major_axis = 6903.50e3  # meters\n",
    "    eccentricity = 0.0011\n",
    "    inclination = np.deg2rad(97.49)\n",
    "    arg_periapsis = 0.0\n",
    "    raan = 0.0\n",
    "    true_anomaly = 0.0\n",
    "\n",
    "    # Chief satellite (inertial Cartesian state)\n",
    "    x_initial_chief = coe2rv(\n",
    "        semi_major_axis=semi_major_axis,\n",
    "        eccentricity=eccentricity,\n",
    "        inclination=inclination,\n",
    "        argument_of_periapsis=np.deg2rad(arg_periapsis),\n",
    "        longitude_of_ascending_node=np.deg2rad(raan),\n",
    "        true_anomaly=np.deg2rad(true_anomaly),\n",
    "    ).reshape(6, 1)\n",
    "\n",
    "    # List of small displacements in RIC/RTN frame [R, T, N] in meters\n",
    "    relative_positions_rtn = [\n",
    "        [50, 0, 0],\n",
    "        [-50, 0, 0],\n",
    "        [0, 50, 0],\n",
    "        [0, -50, 0],\n",
    "        [0, 0, 50],\n",
    "        [0, 0, -50],\n",
    "        [25, 25, 0],\n",
    "        [-25, -25, 0],\n",
    "        [10, -10, 10],\n",
    "    ]\n",
    "\n",
    "    deputies = []\n",
    "    for dr, dt, dn in relative_positions_rtn:\n",
    "        # Convert RTN displacement to ECI frame\n",
    "        r_chief = x_initial_chief[:3].flatten()\n",
    "        v_chief = x_initial_chief[3:].flatten()\n",
    "        r_hat = r_chief / np.linalg.norm(r_chief)\n",
    "        h_vec = np.cross(r_chief, v_chief)\n",
    "        h_hat = h_vec / np.linalg.norm(h_vec)\n",
    "        t_hat = np.cross(h_hat, r_hat)\n",
    "        R_rtn_to_eci = np.column_stack((r_hat, t_hat, h_hat))\n",
    "\n",
    "        delta_r_eci = R_rtn_to_eci @ np.array([dr, dt, dn])\n",
    "        delta_v_eci = np.zeros(3)  # no velocity offset\n",
    "\n",
    "        deputy_state = np.hstack((r_chief + delta_r_eci, v_chief + delta_v_eci)).reshape(6, 1)\n",
    "        deputies.append(deputy_state)\n",
    "\n",
    "    all_states = [x_initial_chief] + deputies\n",
    "    return np.vstack(all_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "formation = 3\n",
    "\n",
    "# Initial conditions and true state vectors (from Tudat)\n",
    "X_initial = get_form_initial_conditions()\n",
    "with open(f\"../data/tudatpy_form{formation}_ts_{int(config.dt)}.pkl\", \"rb\") as file:\n",
    "    X_true = pickle.load(file)\n",
    "X_true = X_true[:, :, : config.K]  # Truncate the true state vector to the simulation duration\n",
    "    \n",
    "dynamics_propagator = Dynamics()\n",
    "\n",
    "# Set the random seed for reproducibility\n",
    "if config.seed is not None:\n",
    "    np.random.seed(config.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Windows:   0%|          | 0/2369 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Newton] Before applying the algorithm\n",
      "Cost function: 350395846.072637\n",
      "Gradient norm: 1853840.3598249613\n",
      "Global estimation error: 5396.547760824044\n",
      "Initial conditions estimation errors: 1713.8119175509528 m, 848.4071788093362 m, 1009.0437593751351 m, 2243.528284839653 m\n",
      "Position estimation errors: 1772.3528851339026 m, 692.6359870047658 m, 1131.1820705737052 m, 2186.1706138955815 m\n",
      "\n",
      "[Newton] Iteration 1\n",
      "Cost function: 6.516059901687807e-07 (-100.00%)\n",
      "Gradient norm: 0.06273886302398939 (-100.00%)\n",
      "Global estimation error: 7.189788401063843 (-99.87%)\n",
      "Initial conditions estimation errors: 0.07658446022505336 m, 0.8407366248297042 m, 1.6099814662826661 m, 2.193085019322614 m\n",
      "Position estimation errors: 0.10760852739512831 m, 1.9905018347082153 m, 1.7829427324285843 m, 1.3165809836085223 m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Windows:   0%|          | 1/2369 [00:07<5:13:15,  7.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Newton] STOP on Iteration 2 (tolerance reached)\n",
      "Cost function = 7.926375222265969e-18 (-100.00%)\n",
      "Gradient norm = 7.31407989563745e-08 (-100.00%)\n",
      "Global estimation error = 7.190255529137863 (0.01%)\n",
      "Final initial conditions estimation errors: 0.07661599595643208 m, 0.8410465881390773 m, 1.6097718178284812 m, 2.1938471283266385 m\n",
      "Final position estimation errors: 0.1075656101737812 m, 1.9904858339852658 m, 1.782995170686607 m, 1.316414788839045 m\n",
      "\n",
      "[Newton] Before applying the algorithm\n",
      "Cost function: 70.23620453861287\n",
      "Gradient norm: 322.4376279270882\n",
      "Global estimation error: 6.992950191982769\n",
      "Initial conditions estimation errors: 0.1075656101737812 m, 1.9904858339852658 m, 1.782995170686607 m, 1.316414788839045 m\n",
      "Position estimation errors: 0.2956667751978278 m, 4.3936749689813785 m, 4.712907717169247 m, 4.05914773166645 m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Windows:   0%|          | 2/2369 [00:13<4:24:27,  6.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Newton] STOP on Iteration 1 (tolerance reached)\n",
      "Cost function = 2.5189151272675474e-18 (-100.00%)\n",
      "Gradient norm = 3.794511124619885e-08 (-100.00%)\n",
      "Global estimation error = 6.959378424253573 (-0.48%)\n",
      "Final initial conditions estimation errors: 0.1075656101737812 m, 1.9904858343110483 m, 1.7829951701297582 m, 1.3164147885322668 m\n",
      "Final position estimation errors: 0.08075683414110638 m, 1.1701162074422404 m, 1.977751331429909 m, 1.1551962130987323 m\n",
      "\n",
      "[Newton] Before applying the algorithm\n",
      "Cost function: 91.13635098915985\n",
      "Gradient norm: 385.4745012248114\n",
      "Global estimation error: 5.952479958011995\n",
      "Initial conditions estimation errors: 0.08075683414110638 m, 1.1701162074422404 m, 1.977751331429909 m, 1.1551962130987323 m\n",
      "Position estimation errors: 0.1539241330196299 m, 3.239648577995921 m, 4.197010499015754 m, 1.7339543478558739 m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Windows:   0%|          | 3/2369 [00:19<4:01:10,  6.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Newton] STOP on Iteration 1 (tolerance reached)\n",
      "Cost function = 1.8552777589884935e-18 (-100.00%)\n",
      "Gradient norm = 3.3609034094867225e-08 (-100.00%)\n",
      "Global estimation error = 5.961700676542658 (0.15%)\n",
      "Final initial conditions estimation errors: 0.08075683412022232 m, 1.170116207493238 m, 1.97775133075642 m, 1.155196213098751 m\n",
      "Final position estimation errors: 0.17992375138886685 m, 1.2514297134801533 m, 1.483991604127284 m, 1.5063916704160167 m\n",
      "\n",
      "[Newton] Before applying the algorithm\n",
      "Cost function: 92.87520458337812\n",
      "Gradient norm: 374.70201008955377\n",
      "Global estimation error: 5.837225143894978\n",
      "Initial conditions estimation errors: 0.17992375138886685 m, 1.2514297134801533 m, 1.483991604127284 m, 1.5063916704160167 m\n",
      "Position estimation errors: 0.4280049541177618 m, 2.4347741208175724 m, 4.390950155751664 m, 2.243733732885621 m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Windows:   0%|          | 4/2369 [00:24<3:48:22,  5.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Newton] STOP on Iteration 1 (tolerance reached)\n",
      "Cost function = 2.680098345521458e-18 (-100.00%)\n",
      "Gradient norm = 3.654128829099898e-08 (-100.00%)\n",
      "Global estimation error = 5.904302781910511 (1.15%)\n",
      "Final initial conditions estimation errors: 0.17992375138655614 m, 1.2514297134329313 m, 1.483991604377007 m, 1.5063916703663596 m\n",
      "Final position estimation errors: 0.1450595931229163 m, 1.7947364251543625 m, 2.773140792720511 m, 2.117479116784588 m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[51], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Run the framework\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(config\u001b[38;5;241m.\u001b[39mH \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m, config\u001b[38;5;241m.\u001b[39mK), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWindows\u001b[39m\u001b[38;5;124m\"\u001b[39m, leave\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m---> 14\u001b[0m     x_init, x_est_k \u001b[38;5;241m=\u001b[39m \u001b[43mnewton\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msolve_MHE_problem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_init\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_true\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mH\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_true\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m     X_est[:, :, k] \u001b[38;5;241m=\u001b[39m x_est_k\n\u001b[1;32m     16\u001b[0m     x_init \u001b[38;5;241m=\u001b[39m dynamics_propagator\u001b[38;5;241m.\u001b[39mf(config\u001b[38;5;241m.\u001b[39mdt, x_init)\n",
      "Cell \u001b[0;32mIn[48], line 95\u001b[0m, in \u001b[0;36mNewton.solve_MHE_problem\u001b[0;34m(self, k, Y, x_init, x_true_initial, x_true_end)\u001b[0m\n\u001b[1;32m     93\u001b[0m J_x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mJ(k, Y, x)\n\u001b[1;32m     94\u001b[0m DJ_x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mDJ(k, Y, x)\n\u001b[0;32m---> 95\u001b[0m HJ_x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mHJ\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;66;03m# Convergence tracking\u001b[39;00m\n\u001b[1;32m     98\u001b[0m cost_value \u001b[38;5;241m=\u001b[39m J_x[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n",
      "Cell \u001b[0;32mIn[48], line 76\u001b[0m, in \u001b[0;36mNewton.HJ\u001b[0;34m(self, k, Y, x_vec)\u001b[0m\n\u001b[1;32m     67\u001b[0m Hf_x \u001b[38;5;241m=\u001b[39m DSTM\n\u001b[1;32m     68\u001b[0m HJ_x \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;241m-\u001b[39m(\n\u001b[1;32m     70\u001b[0m         np\u001b[38;5;241m.\u001b[39mkron(R_inv \u001b[38;5;241m@\u001b[39m (y \u001b[38;5;241m-\u001b[39m h_x), Df_x)\u001b[38;5;241m.\u001b[39mT \u001b[38;5;241m@\u001b[39m Hh_x \u001b[38;5;241m@\u001b[39m Df_x\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;241m+\u001b[39m Df_x\u001b[38;5;241m.\u001b[39mT \u001b[38;5;241m@\u001b[39m Dh_x\u001b[38;5;241m.\u001b[39mT \u001b[38;5;241m@\u001b[39m R_inv \u001b[38;5;241m@\u001b[39m Dh_x \u001b[38;5;241m@\u001b[39m Df_x\n\u001b[1;32m     74\u001b[0m )\n\u001b[1;32m     75\u001b[0m DSTM \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m---> 76\u001b[0m     np\u001b[38;5;241m.\u001b[39mkron(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meye\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m, STM)\u001b[38;5;241m.\u001b[39mT \u001b[38;5;241m@\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdyn\u001b[38;5;241m.\u001b[39mHf(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdt, x_vec) \u001b[38;5;241m@\u001b[39m STM\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;241m+\u001b[39m np\u001b[38;5;241m.\u001b[39mkron(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdyn\u001b[38;5;241m.\u001b[39mDf(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdt, x_vec), np\u001b[38;5;241m.\u001b[39meye(config\u001b[38;5;241m.\u001b[39mn)) \u001b[38;5;241m@\u001b[39m DSTM\n\u001b[1;32m     78\u001b[0m )\n\u001b[1;32m     79\u001b[0m STM \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdyn\u001b[38;5;241m.\u001b[39mDf(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdt, x_vec) \u001b[38;5;241m@\u001b[39m STM\n\u001b[1;32m     80\u001b[0m x_vec \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdyn\u001b[38;5;241m.\u001b[39mf(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdt, x_vec)\n",
      "File \u001b[0;32m~/anaconda3/envs/spacesim-toolkit/lib/python3.10/site-packages/numpy/lib/twodim_base.py:158\u001b[0m, in \u001b[0;36meye\u001b[0;34m(N, M, k, dtype, order, like)\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput must be >= 1-d.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m m[::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m]\n\u001b[0;32m--> 158\u001b[0m \u001b[38;5;129m@set_array_function_like_doc\u001b[39m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;129m@set_module\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21meye\u001b[39m(N, M\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mfloat\u001b[39m, order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m*\u001b[39m, like\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    161\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;124;03m    Return a 2-D array with ones on the diagonal and zeros elsewhere.\u001b[39;00m\n\u001b[1;32m    163\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    205\u001b[0m \n\u001b[1;32m    206\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m like \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "newton = Newton()\n",
    "\n",
    "# Generate observations\n",
    "Y = np.zeros((config.o, 1, config.K))\n",
    "for k in range(config.K):\n",
    "    Y[:, :, k] = config.h(X_true[:, :, k]) + np.random.multivariate_normal(np.zeros(config.o), config.R).reshape((config.o, 1))\n",
    "\n",
    "# Initial guess for the state vector\n",
    "X_est = np.full_like(X_true, np.nan)\n",
    "x_init = X_initial + np.random.multivariate_normal(np.zeros(config.n), config.P_0).reshape((config.n, 1))\n",
    "\n",
    "# Run the framework\n",
    "for k in tqdm(range(config.H - 1, config.K), desc=\"Windows\", leave=False):\n",
    "    x_init, x_est_k = newton.solve_MHE_problem(k, Y, x_init, X_true[:, :, k - config.H + 1], X_true[:, :, k])\n",
    "    X_est[:, :, k] = x_est_k\n",
    "    x_init = dynamics_propagator.f(config.dt, x_init)  # Warm-start for the next MHE problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import save_simulation_data\n",
    "\n",
    "class Args:\n",
    "    monte_carlo_sims = 1\n",
    "    algorithm = \"newton\"\n",
    "    formation = formation\n",
    "    \n",
    "args = Args()\n",
    "X_est_all = []\n",
    "X_est_all.append(X_est)\n",
    "save_simulation_data(args, X_true, X_est_all)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spacesim-toolkit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
